---
key:
title: 'pixelcnn 이해 - 1'
excerpt: 'pixelcnn'
tags: [pixelcnn]
---

내용은 https://github.com/demul/basic_idea/blob/master/Understanding%20PixelCNN/understanding_pixelcnn.md를 참고하였습니다.

![img](https://github.com/demul/basic_idea/raw/master/Understanding%20PixelCNN/images/pixelrnn4.png)

> 자기 회귀 모델은 자신의 결과물을 다시 자신의 input으로 재귀시키는 모델로서 생성모델, 도메인에서는 Auto-Regressive Model은 보편적으로 PixelRNN, PixelCNN과 그 후속, 파생모델들 따위를 일컫는다. 영상을 만들 떄 한번에 처리하지 않고 한 픽셀, 한 채널, 따로 따로 순서대로 만든다, **각 픽셀을 만들 떈 지금까지 생성한 픽셀들의 입력으로 들어가 context(문맥)이 된다**
>

여기서 대문자 x는 영상, 그리고 n은 제곱이니까 이미지에서 2d를 생성한다고 했을 떄 width와 height 일꺼고 소문자 x는 각 픽셀픽셀이다, $p(x_i | x_1, x_2, ..., x_{i-1})$는 이전 픽셀들이 주어졌을 때 $i$번째 픽셀의 조건부 확률이라는 말로, 즉 p(x_i)는 0번째 픽셀부터 i-1까지의 이미 만들어진 픽셀들이 prior로 주어졌을때, i번째 픽셀의 확률을 나타낸다,  그 i가 1부터 n제곱까지 반복하는걸 각 항을 모두 곱한게 영상 x의 확률이라는 의미로, 수식으로 **모델이 이 픽셀에서 만들 값은 지금까지의 픽셀들의 값에 영향을 끼친다**라는 부분이 표현된 수식이다.

![img](https://github.com/demul/basic_idea/raw/master/Understanding%20PixelCNN/images/survey2.png)

그렇기에 각 픽셀이 지금까지의 픽셀들을 참고해 만드니까 결과물의 데이터 분포를 Log Likelihood로 명시적으로 파악할 수 있으며, 매우 안정적인 학습이 가능하고, 한 픽셀 한 픽셀을 확률분포에서 샘플링해가며 만드는 특성 상, 높은 Consistency(일관성)와 Multimodality(다중성)를 보여준다. 

여기서 로그 가능도라는 말은 확률이 계산하기 쉬운 형태로 바뀐다는 말로, $$\log p(x) = \sum_{i=1}^{n} \log p(x_i | x_1, x_2, ..., x_{i-1})$$ 이런식으로 양변에 로그만 취하고 모델의 성능을 평가할 수 있다, 그렇다는 말은 모델간의 성능을 비교할 수도 있고, 모델에게 로그 가능도를 최대화 하는 방향으로 $$\max_\theta \sum_{x \in D} \log p_\theta(x)$$ (세타는 모델 파라미터, D는 학습 데이터셋) 하면 되기 떄문에, 이 목적 함수는 가능도를 직접 최대화 하므로, gan에서 minimax게임을 해서 학습한다거나 하는거랑 달리 단일 목적 함수를 가진다, 그렇기 떄문에 

1. 수렴 보장: 명확한 단일 목적 함수가 있어 수렴이 보장됩니다.

1. 모드 붕괴 없음: GAN에서 발생할 수 있는 모드 붕괴(mode collapse) 문제가 없습니다.

1. 하이퍼파라미터 민감도 감소: 학습 과정이 안정적이어서 하이퍼파라미터 튜닝에 덜 민감합니다.

이러한 **안정적인 학습 장점**이 있고 $$x_i \sim p(x_i | x_1, x_2, ..., x_{i-1})$$ 각 픽셀은 조건부 확률 분포에서 샘플링 하기 때문에 모델 파라미터가 고정되면 완전히 결정적으로 확률 분포가 나온다, 즉, 동일한 이전 픽셀 값들이 주어지면 항상 동일한 조건부 확률 분포가 나오기에 결과가 예측 되는 **일관성** 을 가지게 된다. 

1. 구조적 일관성: 생성된 이미지의 구조적 특성이 일관되게 유지됩니다.

1. 전역적 정합성: 이미지 전체에 걸쳐 일관된 구조와 스타일을 가진 이미지가 생성됩니다.

1. 고전적 확률론적 모델링: 명확한 확률 모델을 따르므로 결과가 예측 가능합니다.

그리고 그 확률분포에서 뽑는건 확률이기 떄문에 $$p_T(x_i | x_{<i}) \propto p(x_i | x_{<i})^{1/T}$$ (여기서 T는 temperature 파라미터, 1보다 커지면 확률 분포가 평탄해져 다양성이 증가, 1보다 작아지면 뾰족해져 더 결정적인 샘플링을 함)에 따라 다양하게 뽑을 수 있는 **다양성**이 존재한다. 즉 동일한 모델로 다양한 이미지를 생성이 가능한데, 여기서 위에 말한 일관성은 **확률분포**가 일관적이라는 거고 거기서 뽑는 게 다양하다는걸 다양하다라고 말하는 거다.

하지만 그렇기에 처리시간이 오래 걸리기떄문에 실시간 처리에 단점이 있다.

![img](https://github.com/demul/basic_idea/raw/master/Understanding%20PixelCNN/images/pixelrnn1.png)

> 위 사진은 PixelCNN, Row LSTM, Diagonal BiLSTM이 픽셀간 Dependency를 구현하는 형태를 나타낸 것이다.

Row LSTM은 이미지를 행 단위로 처리하는 자기회귀 모델이다. 이 모델은 각 픽셀을 예측할 때 같은 행의 왼쪽 픽셀들과 위쪽 행들의 모든 픽셀 정보를 사용한다.

## Row LSTM: 행 기반 이미지 생성

### 작동 원리

Row LSTM은 다음과 같은 방식으로 작동합니다:

1. 이미지를 왼쪽 상단부터 행 단위로 처리합니다.

1. 각 행은 LSTM 유닛을 통해 왼쪽에서 오른쪽으로 순차적으로 처리됩니다.

1. 현재 픽셀 예측에 사용되는 정보:

- i-s(input-to-state): 3×1 마스크 B를 사용해 현재 픽셀 위쪽의 정보를 입력으로 받습니다. (위 쪽 픽셀들의 의존성을 말함)

- s-s(state-to-state): 3×1 마스크 없이 같은 행의 왼쪽 픽셀들의 상태 정보를 활용합니다. (행 쪽 픽셀들의 의존성을 말함)

이 구조는 수평 방향의 의존성을 효과적으로 모델링할 수 있으며, 일부 병렬화가 가능하여 계산 효율성도 어느 정도 확보됩니다.

## Diagonal BiLSTM: 대각선 기반 이미지 생성

Diagonal BiLSTM은 Row LSTM의 한계를 극복하기 위해 고안된 모델로, 이미지를 대각선 방향으로 처리합니다. 이는 보다 다양한 방향의 의존성을 효과적으로 포착할 수 있습니다.

### 작동 원리

Diagonal BiLSTM의 특징적인 작동 방식은 다음과 같습니다:

1. 이미지를 대각선 단위(왼쪽 위에서 오른쪽 아래로)로 구분하여 처리합니다.

1. 각 대각선에서 양방향(Bidirectional) LSTM을 활용합니다:

- 정방향: 대각선의 왼쪽 아래에서 오른쪽 위로 정보 전달

- 역방향: 대각선의 오른쪽 위에서 왼쪽 아래로 정보 전달

1. 각 픽셀 예측에 사용되는 정보:

- i-s: 1×1 마스크 B를 사용하여 직전 대각선의 픽셀 정보를 입력으로 받음 

- s-s: 1×2 마스크 없이 현재 대각선 내의 이전 픽셀 상태 정보를 활용

대각선 처리 방식과 양방향 LSTM의 조합으로 더 복잡한 공간적 의존성을 포착할 수 있어 생성 품질이 향상됩니다.

lstm에서 이미지를 먼저 처리하기위해 pixelcnn이 나오기 전에 나왔던 모델들로 이 논문의 저자는 저 2가지 방법과 pixelcnn까지 3가지 방법을 서로 trade-off하면서 적절한 모델을 골라 쓸 수 있게 하였다.

여기서 i-s는 input to state로 입력값에서 현재값으로 미치는 영향값을 표현한거고 s-s는 state to state로 현재값(이미지)에서 서로 영향을 끼치는거를 말하는대 row는 바로 현재 다루는 픽셀 옆에있는 픽셀값을 의미하는거고 diagonal은 현재 대각선의 픽셀값이 영향을 끼친다, 여기서 no mask라는 걸로, 즉 row에서는 이 영역 내의 모든 픽셀(현재 처리 중인 픽셀 왼쪽에 있는)이 마스킹 없이 그대로 상태 정보에 기여한다는 의미이고 diagonal도 마스킹없이 그대로 이전상태값을 활용한다는 말이다.

> 이 논문에서 설명하는 모델의 Task는 맨 왼쪽, 맨 위, R픽셀에 랜덤한 값을 준 뒤, 이것으로 부터 시퀸셜하게 한 픽셀 한 픽셀씩 Likelihood가 높은 값들만 선택해가면서 그럴듯한(ImageNet이나 CIFAR10 데이터들과 같은 분포를 가지는) 영상을 만들어 내는 것이다.

> NLL을 측정할 때(Evaluation)는, 완전한 이미지 하나를 준 뒤, 각 픽셀을 예측할 때, 이전의 픽셀들이 모두 올바르게 예측되었을 것이라고 가정하고 Context로 이 완전한 Image(즉 Label)의 일부를 사용한다.(일종의 Teacher Forcing 느낌) 그리고 이렇게 예측된 픽셀 값을 Label의 픽셀 값과 비교한 Cross-Entropy-Error를 구한 뒤 저장하고, 예측한 픽셀값은 버리고, 다음 픽셀을 예측할 땐 다시 Label의 픽셀값을 사용한다. 이렇게 저장한 Cross-Entropy-Error를 모두 더한 값을 차원수(CIFAR10의 경우 32x32x3)로 나눈 값을 NLL로 한다.

NLL은 Negative Log Likehood로 음의 로그 가능성이고, 로그 가능성은 앞에서 말했으니 음의 값으로 평가한다는 뜻인데, 

NLL 측정 과정은 다음과 같은 핵심 원리를 따릅니다:

1. Teacher Forcing 기법:

- 모델이 예측할 때 이전 픽셀들의 실제 값(Label)을 사용합니다.

- 이는 모델의 예측 오류가 누적되는 것을 방지하고, 각 위치에서의 순수한 예측 성능을 평가합니다.

2. 픽셀별 확률 계산:

- 각 픽셀 위치에서 모델은 256가지 가능한 픽셀 값(0-255)에 대한 확률 분포를 출력합니다.

- 실제 픽셀 값과 이 확률 분포 간의 크로스 엔트로피를 계산합니다.

3. 결과 정규화:

- 모든 픽셀 위치의 크로스 엔트로피를 합산한 후, 전체 픽셀 수로 나누어 평균 NLL을 구합니다.

먼저 **teacher forcing** 기법이란 순차적 모델을 훈련할 때 사용하는 기법으로 모델이 이전 시점의 자체 예측값 대신 실제 정답(ground truth)을 다음 입력으로 사용하는 방법이다.

일반적인 자기회귀모델은 자체 예측값을 다음 입력으로 사용해서 다음 출력을 예측하는데  teacher forcing을 적용한 평가/훈련 방식은 현재 시점의 출력을 예측 할 때 이전 시점의 예측값 대신 실제 정답을 사용해서 오류가 누적되지 않은 상태에서 각 시점의 예측을 학습하는 방식으로 

1. 이미지의 각 픽셀을 왼쪽 상단부터 순차적으로 처리
2. 픽셀 (i,j)를 예측할 때:
   - 실제 이미지의 (0,0)부터 (i,j-1)까지의 픽셀값을 사용
   - 이전에 예측한 픽셀값은 사용하지 않음
3. 이 과정을 모든 픽셀에 대해 반복

이런식이다, 그니까 지금 여기선 모델이 각 픽셀 위치에서 정확한 조건부 확률을 얼마나 잘 학습했는지 측정하기 위해, 모델의 이론적 성능을 평가하기 위해서 썼다는 소리다.

그래서 모델 예측값이랑 label을 교차엔트로피로 에러값을 구하고, 다음 픽셀에선 저 모델 예측값을 사용하지 않고 다시 실제 label의 이미지 픽셀값을 사용해서 계속 구하고 총 구한 에러값을 더해서 차원수로 나눈걸 NLL로 하겠다는걸로, 

- NLL은 모델이 이미지 데이터 분포를 얼마나 잘 모델링했는지 측정

- 값이 낮을수록 모델이 실제 데이터 분포에 더 가까움을 의미
- 정보 이론적으로는 "모델이 각 픽셀을 인코딩하는 데 필요한 평균 비트 수"로 해석 가능

정보 이론에서 "최대한 효율적인 인코딩하는데 필요한 비트수"를 구하는 그 log의 그거(샤논의 정보 이론에 따르면, 최적의 데이터 압축은 데이터의 실제 확률 분포를 정확히 모델링할 때 달성)에서 NLL에서 log2(e)를 곱하면 bits per dimension(bpd)로 변환할 수 있고 bpd는 이미지의 각 픽셀(차원)을 인코딩하는 데 필요한 평균 비트 수를 나타내는데 그냥 왜 이런 짓을 하냐면 데이터 압축 관점에서의 모델 성능을 직관적으로 보여주기 떄문이다. 간단히 말해, NLL은 모든 픽셀에 대한 크로스 엔트로피 손실의 평균으로, **모델이 실제 이미지 분포를 얼마나 정확하게 모델링했는지를 수치화한 것**이다.

```py
def evaluate(model, test_loader, device):
    model.eval()
    test_loss = 0
    
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            
            # 모델 출력 (Teacher Forcing 방식)
            output = model(data, target if model.n_classes else None)
            
            # 채널별 손실 계산
            loss = 0
            for c in range(data.shape[1]):  # 각 채널에 대해
                # 타겟 이미지 (0-255 정수)
                target_img = (data[:, c] * 255).long()
                output_c = output[:, c]  # [batch, height, width, 256]
                
                # 크로스 엔트로피 손실 계산
                loss += F.cross_entropy(
                    output_c.reshape(-1, 256),  # 각 픽셀의 256가지 값에 대한 확률
                    target_img.reshape(-1)      # 실제 픽셀 값 (0-255)
                )
            
            loss /= data.shape[1]  # 채널 수로 나누어 정규화
            test_loss += loss.item()
    
    return test_loss / len(test_loader)
 
```

 

- 표준 디지털 이미지: 각 픽셀은 0부터 255까지의 정수값으로 표현됩니다.

- RGB 컬러 이미지: 각 픽셀은 3개의 채널(빨강, 초록, 파랑)로 구성되며, 각 채널은 0-255 사이의 값을 가집니다.

- 8비트 표현: 0-255는 8비트(2^8=256)로 표현 가능한 모든 값입니다.

즉 output은 256개의 한 픽셀에 있는 rgb 각 채널의 이산 값의 대한 확률 분포 [0.02, 0.04, ... , 0.01] 이런식으로 256개의 가능한 값의 리스트로 나타내고, target은 실제 이미지 값으로 여기서 pytorch는 toTensor()를 해서 0에서 1 사이의 값으로 정규화했기 떄문에 다시 255를 곱하고, 픽셀의 rgb각 채널의 값은 이산 값이므로 long()을 해서 소수점 떄는거다, 그렇게 하고 나서 실제값이랑 예측값의 크로스 엔트로피를 구한다.

크로스 엔트로피는   CE(y, p) = -Σ y_i * log(p_i) 이렇게 계산하니까 타켓이 지금 원-핫 인코딩이므로 CE(p, q) = -Σ p(x) * log(q(x))
         = -(0*log(q₀) + 0*log(q₁) + ... + 1*log(q_y) + ... + 0*log(q_n))
         = -log(q_y) 이고 이건 "원-핫 인코딩된 타겟의 경우 이는 -log(p_y)로 단순화됨"은 오직 정답 클래스 y의 예측 확률에 -log를 취한 값만 남는다는 의미이다, 즉 그러니까 실제값 y가 어차피 [0,0,0,...1,0] 이런식일테고 거기서 log(p_i)라는 확률값을 곱하면 어차피 해당 값이 아닌 나머지 값들은 0과 곱해져서 사라지고 해당값만 남고 그 해당값의 확률만 로그취한게 남는다.

여기서 pytorch의 cross_entropy()는 logics(원시값)에다가 스프트맥스(합하면 1이 되게 값들을 확률로 만드는거) 하고 거기다 -log를 적용하고 배치 내 모든 샘플의 평균을 계산하는 과정을 거치기 때문에 loss의 입력값에 저렇게 하면 된다.

```py
# 타겟 클래스 인덱스 (예: 클래스 1)
target = 1

# 타겟 클래스의 예측 확률
prob_y = softmax[target]  # 0.24(값 중 가장 큰 값)

# -log 적용
loss = -torch.log(prob_y)  # -log(0.24) ≈ 1.43

# 배치 크기가 3인 경우의 개별 손실값
losses = [1.43, 2.1, 0.7]

# 배치 평균
batch_loss = sum(losses) / len(losses)  # (1.43 + 2.1 + 0.7) / 3 ≈ 1.41

loss += F.cross_entropy(
    output_c.reshape(-1, 256),  # [배치×높이×너비, 256] 형태의 로짓
    target_img.reshape(-1)      # [배치×높이×너비] 형태의 타겟 인덱스 (0-255)
)
```

1. 각 픽셀 위치의 256개 로짓에 softmax 적용 → 각 픽셀값(0-255)의 확률 계산

1. 각 픽셀 위치에서 실제 픽셀값(타겟)에 해당하는 확률에 -log 적용

1. 모든 픽셀 위치에 대한 평균 손실 계산

예를 들어, 한 픽셀의 실제 값이 42이고 모델이 예측한 42의 확률이 0.7이라면, 이 픽셀의 손실은 -log(0.7) ≈ 0.36입니다.

원-핫 인코딩된 타겟의 경우 -log(p_y)로 단순화됨"이란:

- 범주형 타겟(클래스 인덱스)에 대한 크로스 엔트로피는

- 실제 클래스에 해당하는 예측 확률에 -log를 취한 값으로 단순화됨을 의미





