---
key:
title: 'pixelcnn 이해 - 2'
excerpt: 'pixelcnn'
tags: [pixelcnn]
---

> Masked Convolution은 위 그림과 같이 자신의 왼쪽과 위쪽을 제외한 나머지 영역의 Weight를 0으로 만든 Convolution을 의미한다. 즉 Dependency의 방향을 왼쪽, 위로 한정하기 위해 사용한다. Mask A는 현재 연산중인 픽셀의 채널을 Context에 포함하지 않는 방식이고, Mask B는 현재 연산중인 픽셀의 채널을 포함하는 방식이다. 현재 연산중인 픽셀과의 Dependency는 최초에 한번 끊어주면 되므로 Table 1에서 보는 것처럼 Mask A는 최초에 한번만 적용된다.

![img](https://github.com/demul/basic_idea/raw/master/Understanding%20PixelCNN/images/pixelrnn7.png)

여기서 "최초의 한번만 끊어주면 되므로 mask A를 최초에 한번만 적용시킨다"는 말은 pixelCNN에서 첫 입력값(이미지)를 그대로 픽셀값으로 쓰면 치팅 효과가 발생하기 떄문에, 즉 이 마스크를 적용하면 이후 레이어의 특징 맵에는 이미 현재 픽셀의 원본 정보도 없고 그 이후에 mask B를 사용하더라도 원본 정보가 없기 떄문에 자기회귀를 구현 하기도 가능하다, 그리고 여기서 pixelCNN은 lstm처럼 셀을 여러차례 타입스텝으로 도는게 아니라 여러 레이어로 이루어진 신경망이 생성한 부분적 출력(현재까지 생성된 이미지)을 다시 입력으로 사용하여 반복적으로 동작하는(생성할 떄, 학습 할 떄는 병렬적으로 한번에 함) 자기회귀(auto-regressive) 모델 둘의 구조(아키텍쳐)가 다르다.

### LSTM과의 비교

LSTM: 시간적 차원으로 반복 실행되는 단일 셀

- 각 시간 단계(time step)마다 동일한 가중치 사용

- "첫 번째로 돌 때"는 시간 단계 측면에서의 첫 단계

  PixelCNN: 여러 합성곱 레이어가 깊이 방향으로 쌓인 구조

- 각 레이어는 서로 다른 가중치와 기능을 가짐

- "첫 레이어"는 네트워크 깊이 측면에서의 첫 번째 레이어

1. 자기회귀 모델의 핵심 특성:

- 조건부 확률 모델링: p(x_t | x_1, x_2, ..., x_{t-1})

- 순차적 생성: 이전에 생성된 값들을 조건으로 다음 값 생성

1. 두 모델의 공통점:

- 목표: 이미지를 픽셀 단위로 순차적으로 생성

- 확률 모델링: 이전 픽셀들의 조건부 확률 분포 학습

- 자기회귀 원칙: 현재 픽셀은 이전 픽셀에만 의존

lstm은

      1. 첫 픽셀 생성
      2. 그 픽셀을 LSTM 셀의 입력으로 사용
      3. 두 번째 픽셀 생성
      4. 첫 번째와 두 번째 픽셀을 바탕으로 세 번째 픽셀 생성
      5. 이 과정을 반복...

piexlCNN은

      1. 빈 이미지로 시작
      2. 첫 픽셀 위치의 확률 분포 계산 → 첫 픽셀 생성
      3. 첫 픽셀이 채워진 이미지를 전체 네트워크에 통과 → 두 번째 픽셀 생성
      4. 두(첫 번쨰픽셀이랑 두 번쨰픽셀) 픽셀이 채워진 이미지를 전체 네트워크에 통과 → 세 번째 픽셀 생성
      5. 이 과정을 반복...

- LSTM: 동일한 셀의 순차적 실행을 통한 자기회귀 구현 (시간적 전개)

- PixelCNN: 마스킹된 합성곱과 깊은 네트워크를 통한 자기회귀 구현 (공간적 전개)

이라고 할 수 있다.

정확하게 pixelCNN이 도는 걸 이해하자면 예를 들어 12번쨰 픽셀을 생성한다고 하자면

```
생성 순서:
[ 1,  2,  3,  4]
[ 5,  6,  7,  8]
[ 9, 10, 11, 12]

12번째 픽셀 생성 시 네트워크 입력:
[ A,  B,  C,  D]  ← 이미 생성된 픽셀들 (1-11번)
[ E,  F,  G,  H]
[ I,  J,  K,  0]  ← 12번 위치는 아직 비어 있음(0)
                   (이 위치의 값을 예측하기 위함)
```



### 정확한 생성 과정

1. 초기 상태: 빈 이미지(모든 픽셀이 0)로 시작

1. 1번 픽셀 생성:

- 빈 이미지를 네트워크에 통과시킴

- 1번 위치의 확률 분포 계산

- 샘플링하여 1번 픽셀 채움

1. 2번 픽셀 생성:

- 1번 픽셀이 채워진 이미지 전체를 네트워크에 통과

- 2번 위치의 확률 분포 계산

- 샘플링하여 2번 픽셀 채움

1. ...동일한 과정 반복...

1. 12번째 픽셀 생성:

- 1번부터 11번까지 픽셀이 채워진 이미지 전체를 네트워크에 통과

- 12번 위치의 확률 분포 계산

- 샘플링하여 12번 픽셀 채움



즉 지금까지의 만들어진 픽셀들이 현재 내가 만들려는 위치의 픽셀에 영향을 끼친다는 말인거다, lstm과는 결이 다른 구조인거다.

## Row LSTM

![img](https://github.com/demul/basic_idea/raw/master/Understanding%20PixelCNN/images/pixelrnn3.png)

> 수식(3)에서 주의할 점은 **c, h, x는 Trainig시엔 병렬처리를 위해 h x n x 1의(여기서 h는 채널 수) 차원(한 행 전체)을 가진다는 것이다.**
>
> 하지만 **c_i-1과 h_i-1은 Inference시엔 h x 3 x 1(한 행 위의 픽셀 3개)의 차원을 가진다. 또한 x_i 역시 h x 3 x 1(자신 + 양 옆 픽셀, 단 오른쪽 픽셀은 Mask되므로 연산에 반영되진 않음)의 차원을 가진다. 다만 h_i는 Output으로 나오는 단 한 픽셀이므로 h x 1 x 1의 차원을 가진다.** 왜냐하면 Inference시에는 Trainig시처럼 이전 픽셀이 정확하게 예측되었다는 가정을 할 수 없으므로(Teacher Forcing 방법 사용이 불가능하므로) 한 픽셀 한 픽셀을 Sequential하게 만들어 나가기 때문이다.

이  ROW LSTM 설명은 훈련과 생성의 처리 과정을 설명하는 걸로

### 1. 학습 시(병렬 처리)

- 병렬 처리의 이점:

- 학습 시에는 실제 이미지가 있으므로, 한 행 전체를 한 번에 처리 가능

- Teacher Forcing: 실제 값을 사용하여 다음 예측을 수행

- 차원 구성:

- c, h, x: h × n × 1 차원

- h: 채널 수 (hidden state 크기)

- n: 한 행의 픽셀 수 (이미지 너비)

- 즉, 한 행 전체를 병렬로 처리

- 연산 과정:

- 한 행의 모든 픽셀에 대해 동시에 hidden state 계산

- 각 픽셀은 자신의 왼쪽과 위쪽 픽셀에만 의존(마스킹)

### 2. 추론 시(순차 처리)

- 순차 처리의 필요성:

- 추론 시에는 이미지를 생성해야 하므로, 한 픽셀씩 순차적으로 처리 필요

- 이전 예측이 다음 예측의 입력으로 사용됨

- 차원 구성:

- c_i-1, h_i-1: h × 3 × 1 차원

- 윗 행의 3개 픽셀(현재 위치 중심으로 왼쪽, 위, 오른쪽)의 상태

- x_i: h × 3 × 1 차원

- 현재 행의 3개 픽셀(자신, 왼쪽, 오른쪽)

- 그러나 오른쪽 픽셀은 마스킹되어 실제 연산에 사용되지 않음

- h_i: h × 1 × 1 차원

- 출력은 현재 처리 중인 한 픽셀에 대한 hidden state

여기서 n은 한 이미지의 너비(행)를 말한다, 이름이 row니까 한 줄마다 트레이닝 한다는 말인듯 하다, 

![image-20250429031331004](https://raw.githubusercontent.com/kirity1/blogimg/master/uPic/image-20250429031331004.png)

즉 결국 이 수식은 x에 대해 

- 학습 시: 이 연산을 행 전체에 대해 병렬로 수행

- 추론 시: 한 픽셀씩 순차적으로 수행, 이전 픽셀의 상태를 사용

이렇게 돌아간다고 생각하면 될 듯 하다.

```
학습 시(병렬 처리):
한 행 전체를 한 번에 처리
[픽셀1, 픽셀2, 픽셀3, ..., 픽셀n]
↓      ↓      ↓           ↓
[출력1, 출력2, 출력3, ..., 출력n]

추론 시(순차 처리):
한 픽셀씩 처리
[픽셀1] → [출력1]
  ↓
[픽셀2] → [출력2]
  ↓
[픽셀3] → [출력3]
  ↓
  ...
```

teacher forcing이 불가능하므로라는 의미는

- Teacher Forcing의 의미:

- 학습 시: 다음 픽셀 예측에 이전 픽셀의 실제 값을 사용

- 추론 시: 다음 픽셀 예측에 이전에 생성된 값(예측값)을 사용

- 중요한 차이점:

- 학습: 모든 이전 픽셀 값을 미리 알고 있음

- 추론: 이전 픽셀 값은 모델이 방금 생성한 값(불확실할 수 있음)

1. 자기회귀적 의존성:

- 각 픽셀은 이전 픽셀의 값에 의존

- 다음 픽셀을 예측하려면 이전 픽셀의 값이 필요

1. Teacher Forcing 부재의 영향:

- 추론 시에는 실제 값을 사용할 수 없음

- 따라서 예측값을 다음 예측의 입력으로 사용해야 함

- 이것이 순차적 생성을 강제함

즉 학습할 떈 이미 이미지라는게 있기 떄문에 내 왼쪽에 있는 픽셀을 바로 참고해서 학습할 수 있지만(설령 내 왼쪽에 있는 픽셀이 학습이 덜 끝났더라도 그것과는 별개니까), 그리고 

1. 학습 시 LSTM 상태 전파:

- 각 픽셀 위치에서 LSTM 셀은 h(t-1)와 c(t-1)를 입력으로 받음

- 이 상태들은 실제 이미지의 왼쪽/위쪽 픽셀 값으로부터 계산됨

- 병렬 계산: 한 행의 모든 픽셀 위치에 대해 동시에 계산 가능

1. 생성 시 LSTM 상태 전파:

- 각 픽셀 위치에서 역시 h(t-1)와 c(t-1)를 입력으로 받음

- 그러나 이 상태들은 모델이 생성한 왼쪽/위쪽 픽셀 값으로부터 계산됨

- 순차 계산: 반드시 한 픽셀씩 순서대로 계산해야 함

즉 h(t-1)이랑 c(t-1) 또한 이미 정해져 있기 떄문에 위쪽의 픽셀 3개랑 왼쪽의 픽셀 1개의 참고가 한번에 병렬적으로 가능하다는 말이다, 하지만 생성시에는 그게 불가능 하기떄문에 순차적으로 한 픽셀씩 해야한다, 그러므로 **이것이 PixelRNN/LSTM이 학습은 효율적으로 할 수 있지만, 생성은 필연적으로 느릴 수밖에 없는 근본적인 이유**라고 할 수 있다. 

그래서 n은 이미지의 너비라고(한번에 행으로 병렬적으로 처리되니까) 두는 이유다, 그리고 생성시에는 3인 이유(위쪽의 non-masked인 3개의 픽셀, 그리고 왼쪽에 하나 참조할 떄도 원래는 마스크가 3x1인데 단지 masked되서 [1,0,0]으로 해당 픽셀이랑 미래픽셀값인 오른 쪽은 없게 만듬)이기도 하다,

> 여기서 혼동이 생길 수도 있는데, PixelCNN에서 Evaluation과 Inference는 전혀 다른 차원의 문제다. Evaluation도 Label이 있는 데이터를 기준으로 Teacher Forcing 상황을 가정해서 병렬적으로 할 수 있지만, Inference는 Label을 모르는 상태이므로 반드시 한 픽셀 한 픽셀 Sequential하게 만들어 나가게 된다. 즉 병렬처리를 할 수 없는 상황이므로 h와 x는 h x 3 x 1의 차원을 가진 Parameter로 봐야 Trainig 방식과 Inference 방식 간의 혼동을 막을 수 있다.

장황하게 앞에서 설명한 부분이 결국 이 말에 해당된다.

> 이제 Inference시에, 맨 위, 맨 왼쪽 픽셀부터 이러한 방식으로 한 픽셀 한 픽셀 만드는 상황을 생각해보자. 각 픽셀은 상단으로 역삼각형 형태의 Dependency를 갖게 되므로, 우측 하단으로 Context에 반영해야 하지만, 반영하지 못하는 꽤 큰 영역이 생기게 된다. 이런 영역을 Blind Spot이라고 한다. Row LSTM은 이러한 Blind Spot으로 인해 밑에 설명할 Blind Spot이 아예 없는 Diagonal BiLSTM에 비해 높은 NLL을 갖는다.(당연히 높을 수록 안 좋은 Score다.) 다만 더 간단한 연산방식으로 Diagonal BiLSTM에 비하면 더 빠른 속도를 보여준다.

```
Blind Spot 영역 (올바른 표현):
X X X X X X X   ← 이전 행들
 X X X X X X    
  X X X X X     ← Row LSTM은 이 영역의 많은 부분에
   B B B B        직접 접근할 수 없음 (B: Blind Spot)
    X X X      ← 현재 행 바로 위 3픽셀만 직접 접근
     - -       ← LSTM 상태 전파
      O        ← 현재 생성 중인 픽셀
  
```

이런 느낌이라 보면 될 듯 하다.

## Diagonal BiLSTM

![img](https://github.com/demul/basic_idea/raw/master/Understanding%20PixelCNN/images/pixelrnn8.png)

> Diagonal BiLSTM은, 한 픽셀이 자신 바로 위의 한 픽셀과, 자신 왼쪽의 한 픽셀로 부터 state를 전달받는 과정을 효율적으로 병렬화하기 위해서 Feature Map을 Skew하는 트릭을 사용한다. 이렇게 하면 1 x 2 모양 Convolution 커널하나로 왼쪽, 위 픽셀로 부터 현재 픽셀로 State를 전달할 수 있다. Diagonal BiLSTM에서는 이 1 x 2 Non-Masked Convolution 커널이 State-to-State 커널이 된다. 또한 자기 자신으로부터도 State를 전달받아야 하므로 1 x 1 Masked Convolution을 사용하는데 이게 Input-to-State 커널이 된다.

### 1. 기본 의존성 패턴

각 픽셀은 두 가지 주요 정보 소스를 가집니다:

- 바로 위의 픽셀: 이전 행에서 오는 상태 정보

- 바로 왼쪽의 픽셀: 같은 행의 이전 위치에서 오는 상태 정보

이 두 정보를 모두 활용하면서 병렬 처리를 하기 위해 Skew 트릭을 사용합니다.

## 2. Skew 트릭의 작동 원리

이미지의 Skew 변환은 다음과 같이 작동합니다:

1. 입력 변환(왼쪽 → 오른쪽):

- 원본 이미지에서 각 행을 이전 행보다 한 픽셀씩 오른쪽으로 이동

- 이렇게 하면 대각선 방향의 픽셀들이 같은 열에 정렬됨

1. 병렬 처리 이점:

- 스큐된 이미지에서는 같은 열에 있는 픽셀들이 서로 독립적

- 따라서 한 열의 모든 픽셀을 동시에(병렬로) 처리 가능

1. 출력 복원(오른쪽 → 왼쪽):

- 계산 완료 후 각 행을 다시 왼쪽으로 이동시켜 원래 형태로 복원

## 3. 커널 구조와 역할

Diagonal BiLSTM에서는 두 가지 주요 커널을 사용합니다:

### State-to-State 커널 (s-s)

- 크기: 1×2 (높이×너비)

- 마스킹: Non-Masked (마스킹 없음)

- 역할: 이전 상태 정보 전달

- 동작 방식:

- 스큐된 입력에서 1×2 커널은 "왼쪽 위"와 "바로 왼쪽" 픽셀의 상태를 동시에 캡처

- 이것이 현재 픽셀의 새로운 상태 계산에 사용됨

### Input-to-State 커널 (i-s)

- 크기: 1×1 (단일 픽셀)

- 마스킹: Masked B (현재 위치 포함)

- 역할: 현재 픽셀의 입력 정보 처리

- 동작 방식:

- 현재 픽셀 위치의 입력값을 처리

- "B" 타입 마스크는 현재 위치의 정보를 포함

## 4. 전체 처리 흐름

이미지 처리 흐름은 다음과 같습니다:

1. 스큐 변환 적용:

- 원본 이미지를 행별로 오른쪽으로 이동시켜 스큐 변환

1. 병렬 처리:

- 스큐된 이미지의 각 열에 대해 LSTM 연산 병렬 수행

- 1×2 Non-Masked 커널로 state-to-state 연산

- 1×1 Masked 커널로 input-to-state 연산



1. 역변환 적용:

- 계산된 출력을 다시 원래 형태로 되돌리기 위해 왼쪽으로 이동

## 5. 이미지 예시 설명

제공된 Figure 3 이미지에서:

- 왼쪽: 원본 이미지 형태

- 빨간색 픽셀은 현재 처리 중인 픽셀

- 파란색 영역은 이미 처리된 픽셀들

- 흰색 화살표는 상태 전달 방향을 표시

- 오른쪽: 스큐 변환 후 이미지

- 각 행이 오른쪽으로 한 픽셀씩 이동됨

- 이제 대각선 관계에 있던 픽셀들이 같은 열에 정렬

- 1×2 커널이 효율적으로 상태 정보를 전달 가능

## 6. 장점 요약

- 병렬 처리 가능: 스큐 트릭으로 대각선 방향의 병렬 처리 가능

- 완전한 수용 영역: Blind Spot 없이 모든 이전 픽셀 정보 활용

- 효율적인 상태 전달: 간단한 1×2, 1×1 커널로 복잡한 의존성 구현

그러니까 digonal은 row가 행으로 처리한다면 여기는 열로 병렬처리를 시도하는데, 위쪽 픽셀은 같은 열에 있어 먼저 계산되어야 하는 문제가 있다. (병렬화 방해) 여기서 저런 트릭을 이용해서 이전 열에다가 모든 의존적인 픽셀들을 넣어서 한번에 계산을 처리한다는 말로, 그전에는 왼쪽 픽셀은 이전 열이라 먼저 계산되고 그 다음에 위쪽 픽셀이 같은 열이여서 병렬처리가 안된거였으므로 한번에 같은 열을 모두 의존적인 픽셀(s-s)를 넣어 처리한다, 그래서 1x2의 커널은 저 두개의 픽셀을 의미한다고 볼 수 있다, 그리고 1x1이야말로 오른쪽아래에 있는 지금 학습하고자하는 픽셀을 의미하는거다, 시각적으로 보자면

```
처리 순서 (왼쪽 위부터 오른쪽 아래로):
1  2  3  4
5  6  7  8
9  10 11 12
13 14 15 16
```

여기서 픽셀 11을 처리하려면:

- 픽셀 7(위쪽)의 정보 필요

- 픽셀 10(왼쪽)의 정보 필요

문제점:

- 순차적 제약: 10번 픽셀이 계산되어야 11번 픽셀 계산 가능

- 열 내 의존성: 같은 열에 있는 픽셀들(3→7→11→15)은 순차적으로 처리해야 함

```
Skew 변환 후:
1 2 3 4
  5 6 7 8
    9 10 11 12
      13 14 15 16
```

- 대각선 관계에 있던 픽셀들이 다른 열로 정렬됨

- 원래 같은 열에 있던 픽셀들(3, 7, 11, 15)이 서로 다른 열로 분리됨
- 각 픽셀은 자신의 "왼쪽 위"와 "바로 왼쪽" 픽셀에 의존

- Skew 변환으로 이 두 의존 픽셀이 모두 이전 열에 위치하게 됨

- 변환 후 같은 열에 있는 픽셀들은 서로의 계산에 필요하지 않음

- 각 픽셀은 오직 이전 열의 픽셀들에만 의존

  

- 픽셀 11을 처리하려면 (Skew 변환 후 위치):

  - 픽셀 7(왼쪽 위 대각선)의 정보 필요

  - 픽셀 10(왼쪽)의 정보 필요

  

  중요 포인트: 7과 10은 모두 11보다 이전 열에 위치

  같은 열에 있는 다른 픽셀들(예: 스큐된 위치의 3, 15)은:

  - 픽셀 11의 계산에 필요하지 않음

  - 픽셀 11도 이들의 계산에 필요하지 않음

즉 열은 순차적으로 처리되더라도 그 열 안에는 병렬적으로 처리가 가능해진다는 말이다.

> 여기서 1 x 1 커널인데 Masked Convolution 커널이라는게 도대체 무슨 뜻인지 헷갈릴 수 있다. 하지만 위 Masked Convolution 설명을 다시 보면 Masked Convolution은 채널간에도 Mask를 적용하므로, 1 x 1이라서 x축, y축 차원으로는 Masking이 없지만 채널 차원으로 Masking이 있는 Convolution이라고 생각하면 쉽게 이해할 수 있다.

여기서 말 그대로라서 이해가 어려운 부분은 없지만 한 가지 참고해야 할 건 채널간의 masking, PixelCNN과 BiLSTM의 1×1 Masked Convolution은 R - f(R) 같은 대응이 아닌 

- R 출력: "R 입력만 사용"

- G 출력: "R과 G 입력을 혼합"

- B 출력: "R, G, B 모두 혼합"

이런 느낌이다

![PixelCNN](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAP8AAADGCAMAAAAqo6adAAABBVBMVEUAAAD4zszV6NTa6Pz709Hf7P8cK0D8z8+/vpnE3sDa7NSFoc6vxefJeHUfMEaZwYZ8pmWLps/XiYbb7dusVVJqh7K316zjop+nzpZDExAsQh2ctt2OQT6TQ0BOJCJmjFCHPjtwMzE/HRs7US5VJyVBWjMzFxZ6NzUUCQkOEws8GxqAOjckERBIIR8rExMaDAsQFw1lLiy8XVmnlmybxIFxkcWxoXafzI6mw5KzoLKhsdItFQycR0EAAAqKODaiQkGkVkidY0yOiVaGrWK5U1EdOR6MomIkMht3Vj+BlFpcfkgxDhOLrGaBcExyc0k1SipZHx3AUk07MB1ok09IaDQPFBuSf1dJLfI8AAAD1klEQVR4nO2dCVPTQBSA6wkIKAgqSpImERJom3LI4YGgtIriff7/n+KWFknbTZrskE55/b4ZhpJ0Z/Llvd23u22G0vasGc927hmxsztvxvTdUhHM3jRjcmrBiDvTt8yYuV2Q/zUTJianrhuh/G+YgD/++OOPP/74448//vjjjz/++OOPP/74448//vjjjz/++OOPP/74448//vjjjz/++OOPP/74448//vjjjz/++I+j/3Cf/1oYsee/tu+bsbe/lMjz5FNL+7vLOl6c8VJ7rs18Mc//XTqvVuyDtPOvtUcPj968PW58y91u1PCqR81mmL/du+P3jcbcyeVf0JDxDprNZi13s/qHj41G47SACxo2vtVMTX9tG8/6VDr+3Fgt4oKGi2/XFr18TTYsLyqVyl++zm0Wc01DJLJVF4jytPC37FZ3Ka+WTq5++kfWRr4Gdbd9t04FpH4r+fPpB6EbtH6vy9B37Fxvr4TVoP1Khr5v56l7NTf0Oy/LIvRzRT/yrPr5axn6kZU9+jUrViOE6GePvu+5F7dqXYa+Y2V9Z3DR71tIGfoyFr6gGgaxP6VEP2PyR55b7zogQz9j4VOjnt99RIZ+tuiritd7l4ToW2uD31S3+ldFMvQje7C+munWe4+tl58Wcj1DZmVw8vv/5/lxpER/0NCnVrgVzeExib7TP+qdIST6A7Y76vaWfi9IRvQHFL4odPW3R8rQlzrnV/N8Xb9vMQbJr+b5fRWvwxhE3+md58cRH3016vlJ56QMfcmFT1W8lH4hJvkTJr1B3xqvGyHJnzDn96vV1OngppToaw9H1f5VTjcyou9oO7jKfM0qJ46Yvq856MT3dBOQoa/b7kiveB2E6PcXPjXPH7wFsllO+27PlaE/+Sv69X0vQqLfm/wVN8yy9ys0+o5mX0+LlOh3Fb7A3sqS+QqJ0VcVL+NnXmLqfqzvB3b6PD+ODP34J7xqppvhM4828oa+KHlvR4OU6J8HvDJwnh9nXVj0V7z0FW4vMqJ/PvRlr3gdREVfzXbytRM19OXr92cISv7I9XJ+s1dM9F31E2Za5XQjJPrumhr18ma+oMLneNW8mV8Sk/zOgUnsS1ep8EWPk/n+4zDx3M8nKfz6nXzuril/CvHffmTG3tJDM6ZnzFgeqf9/ODE5tWD6/O9IPf/K88/4448//vjjjz/++OOPP/74448//vjjjz/++OOPP/74448//vjjjz/++OOPP/74448//vjjjz/++OOPP/7444//6PoP9/8fjtrzX4uG/J0zo/HAlGL8AQAAAAAAAAAAAAAAAEAM/wDOJ1QklBmSngAAAABJRU5ErkJggg==)

왜 저렇냐면 

- 자기회귀 모델의 핵심 원칙:

- 현재 값은 이전 값들에만 의존해야 함

- 미래 값에 의존하면 안 됨

- 채널 차원으로 확장:

- 채널을 처리하는 순서: R → G → B

- 이 순서에서 G는 R의 "미래", B는 R과 G의 "미래"로 간주

대충 이런 듯 하다. 일단 이렇게 학습할 떈 병렬처리를 하는데

> 이제 Inference시에, 맨 위, 맨 왼쪽 픽셀부터 이러한 방식으로 한 픽셀 한 픽셀 만드는 상황을 생각해보자. 각 픽셀은 자신을 기준으로 -90º ~ 0º 범위에 있는 모든 픽셀에 Dependency를 갖게 된다. 그러나, 현재 행을 제외한 0º ~ 90º 범위에 있는 픽셀들은 Dependency를 가져야 하나 여전히 갖지 못한 Blind Spot이 된다. 이를 해결하기 위해 간단한 트릭이 적용된다.
>
> 오른쪽->왼쪽 Hidden State Map(0º ~ 90º)을 왼쪽->오른쪽 Hidden State Map(-90º ~ 0º)에 간편하게 더해주기 위해서, Figure 3과 같은 방식으로 Parallelization 하되(이 경우 왼쪽으로 Skew) 아웃풋 맵을 전부 한칸씩 밑으로 내려서, 왼쪽->오른쪽 Hidden state에 더한다. 만약 한칸 씩 밑으로 안 내린다면 해당 픽셀이 미래 정보(자기와 같은 열 오른쪽에 있는)를 보게된다.
>
> 이와 같은 방법으로 두 Hidden State Map들을 더하면 Blind Spot이 아예 없는 것을 알 수 있다. Diagonal BiLSTM은 이러한 특성으로 인해 이 논문에 소개된 모델들 중 가장 낮은 NLL과 가장 느린 속도를 보여준다.

생성 할 떄는 왼쪽으로 skew하여 제한적 병렬을 할 수도 있다고 하는데 내용이 길기 떄문에 생략한다.

![img](https://github.com/demul/basic_idea/raw/master/Understanding%20PixelCNN/images/pixelrnn9.png)

> LSTM Gate를 사용하지 않고도 각 픽셀이 좌상단에 Dependency를 갖게 할 수 있는 방법으로, PixelCNN이 있다. 위 그림에서 보는 것처럼 Masked Convolution 커널을 중첩시키는 것 만으로도 이를 구현할 수 있다. 다만 Dependency Filed가 중첩된 Layer수에 따라 선형적으로 증가한다는 점(즉 충분히 Convolution 커널을 쌓지 않으면 Dependency Filed 크기가 작다는 점), LSTM Gates와 같은 Multiplicative Unit이 없어 모델의 표현력이 떨어진다는 점, 그리고 Row LSTM처럼 Blind Spot이 존재한다는 점 등의 한계로 인해 이 논문에 소개된 세 모델 중 가장 높은 NLL을 보여준다. 다만 느리기로 악명높은 LSTM Unit을 아예 사용하지 않기 때문에 가장 빠른 속도를 가지고 있다.

이게 앞에서 말한 lstm과 pixelCNN의 차이점이다

