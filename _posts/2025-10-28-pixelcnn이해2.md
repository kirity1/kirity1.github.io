---
key:
title: 'pixelcnn 이해 - 3'
excerpt: 'pixelcnn'
tags: [컴퓨터비전]
---


## Row LSTM

![img](https://github.com/demul/basic_idea/raw/master/Understanding%20PixelCNN/images/pixelrnn3.png)

> 수식(3)에서 주의할 점은 **c, h, x는 Trainig시엔 병렬처리를 위해 h x n x 1의(여기서 h는 채널 수) 차원(한 행 전체)을 가진다는 것이다.**
>
> 하지만 **c_i-1과 h_i-1은 Inference시엔 h x 3 x 1(한 행 위의 픽셀 3개)의 차원을 가진다. 또한 x_i 역시 h x 3 x 1(자신 + 양 옆 픽셀, 단 오른쪽 픽셀은 Mask되므로 연산에 반영되진 않음)의 차원을 가진다. 다만 h_i는 Output으로 나오는 단 한 픽셀이므로 h x 1 x 1의 차원을 가진다.** 왜냐하면 Inference시에는 Trainig시처럼 이전 픽셀이 정확하게 예측되었다는 가정을 할 수 없으므로(Teacher Forcing 방법 사용이 불가능하므로) 한 픽셀 한 픽셀을 Sequential하게 만들어 나가기 때문이다.

이  ROW LSTM 설명은 훈련과 생성의 처리 과정을 설명하는 걸로

#### Row LSTM의 동작 원리

Row LSTM은 이미지의 한 행(Row)을 따라가며 연산을 수행한다. 이때 LSTM 게이트 연산(Input, Forget, Output)에는 $3 \times 1$ 크기의 1D Convolution이 사용된다. 이 구조적 특징 때문에 학습과 추론 과정에서 데이터 처리 방식이 완전히 달라진다.

- **① 학습 시 (Training): 병렬 처리 (Parallelization)**

  학습할 때는 이미 완성된 정답 이미지가 우리 손에 있다. 즉, $t$ 시점의 픽셀을 예측하기 위해 $t-1$ 시점의 계산이 끝나길 기다릴 필요가 없다. 이미 정답을 알고 있기 때문에 **Teacher Forcing**을 적용할 수 있다.

  - **동작:** 이미지의 한 행(Row) 전체를 통째로 입력으로 넣는다.
  - **차원 ($h \times n \times 1$):**
    - $h$: 히든 채널 수
    - $n$: 이미지의 너비 (행 전체 길이)
  - **결과:** 입력 $x$, 셀 상태 $c$, 히든 상태 $h$ 모두 행 길이 $n$만큼 동시에 병렬 연산이 수행된다.

  **② 추론 시 (Inference): 순차 처리 (Sequential)**

  문제는 실제로 이미지를 생성할 때다. 이때는 정답지가 없다. 내가 방금 생성한 픽셀이 다음 픽셀의 입력이 되어야 하므로, 필연적으로 **한 땀 한 땀 순차적**으로 진행해야 한다.

  - **동작:** 픽셀 단위로 스텝을 밟으며 진행한다.
  - **차원 ($h \times 3 \times 1$):**
    - 왜 $3$인가? 바로 **Convolution Kernel Size**가 $3$이기 때문이다.
    - **$c_{i-1}, h_{i-1}$:** 현재 픽셀을 만들기 위해 **내 바로 위쪽 행의 상태 3개(왼쪽 위, 바로 위, 오른쪽 위)**를 참고한다.
    - **$x_i$:** 입력 데이터 역시 커널 크기에 맞춰 처리되지만, 마스킹(Masking)에 의해 미래 정보(오른쪽)는 차단된다.
  - **결과:** $h \times 1 \times 1$. 주변 정보를 취합하여 단 하나의 픽셀(히든 상태)을 출력한다.

위 수식은 이 과정을 수학적으로 나타낸 것이다.

LSTM의 게이트 연산(input, forget, output, content)이 수행될 때, $x$와 $h$에 대해 합성곱(Convolution, $\circledast$) 연산을 수행한다는 것을 알 수 있다.

결론적으로 이 수식이 돌아가는 메커니즘을 한 줄로 요약하면 이렇다.

> **"학습할 때는 행 전체($n$)를 한 방에 병렬로 밀어버리고, 생성할 때는 커널 크기($3$)만큼의 주변을 살피며 한 땀 한 땀 순차적으로 채워나간다."**

![image-20250429031331004](https://raw.githubusercontent.com/kirity1/blogimg/master/uPic/image-20250429031331004.png)

즉 결국 이 수식은 x에 대해 

**학습 시:** 행 전체($n$)에 대해 **병렬(Parallel)**로 수행

**추론 시:** 한 픽셀씩 **순차적(Sequential)**으로 수행하며 이전 상태를 갱신

이렇게 돌아간다고 생각하면 될 듯 하다.

```
[학습 시: 병렬 처리]
이미 정답을 알고 있으므로 한 행 전체를 한 번에 계산
[픽셀1, 픽셀2, 픽셀3, ..., 픽셀n] (Ground Truth)
    ↓      ↓      ↓            ↓
[출력1, 출력2, 출력3, ..., 출력n]

[추론 시: 순차 처리]
앞 픽셀이 나와야 다음 입력을 알 수 있음
[픽셀1] → [출력1]
              ↓ (입력으로 사용)
            [픽셀2] → [출력2]
                          ↓
                        [픽셀3] → ...
```

**1. 학습할 때 ($n$): **

학습할 때는 Teacher Forcing을 쓴다. 즉, 우리는 이미 완성된 이미지(Ground Truth)를 가지고 있다. 내 왼쪽 픽셀이나 위쪽 픽셀들의 값이 무엇인지 이미 확정되어 있다는 뜻이다.

따라서 LSTM의 상태 $h_{t-1}, c_{t-1}$를 계산하기 위해 굳이 앞 단계의 연산이 끝나길 기다릴 필요가 없다. 그냥 정답 값을 넣어서 행 전체($n$)를 동시에 돌려버리면 된다. 그래서 차원이 $h \times n \times 1$이 된다.

**2. 추론할 때 ($3$): **

문제는 실제로 이미지를 생성할 때다. 이때는 정답지가 없다. 내가 방금 생성한 예측값(Prediction)을 믿고 다음 입력으로 써야 한다. 따라서 필연적으로 앞 픽셀의 연산이 끝나야만 다음 스텝을 밟을 수 있는 순차적 제약이 걸린다.

이때는 한 번에 한 픽셀만 본다. Row LSTM은 자신의 위쪽 라인에서 [왼쪽 위, 바로 위, 오른쪽 위] 3개의 정보를 취합하므로 커널 사이즈인 $3$만큼의 차원($h \times 3 \times 1$)을 가지게 된다.

(참고로 현재 행을 볼 때는 자기 자신과 미래인 오른쪽을 볼 수 없으므로 마스킹을 통해 사실상 왼쪽 1개만 참조하게 된다.)

즉 학습할 떈 이미 이미지라는게 있기 떄문에 내 왼쪽에 있는 픽셀을 바로 참고해서 학습할 수 있지만(설령 내 왼쪽에 있는 픽셀이 학습이 덜 끝났더라도 그것과는 별개니까)

즉 h(t-1)이랑 c(t-1) 또한 이미 정해져 있기 떄문에 위쪽의 픽셀 3개랑 왼쪽의 픽셀 1개의 참고가 한번에 병렬적으로 가능하다는 말이다, 하지만 생성시에는 그게 불가능 하기떄문에 순차적으로 한 픽셀씩 해야한다, 그러므로 **이것이 PixelRNN/LSTM이 학습은 효율적으로 할 수 있지만, 생성은 필연적으로 느릴 수밖에 없는 근본적인 이유**라고 한다고 한다. 

그래서 n은 이미지의 너비라고(한번에 행으로 병렬적으로 처리되니까) 두는 이유다, 그리고 생성시에는 3인 이유(위쪽의 non-masked인 3개의 픽셀, 그리고 왼쪽에 하나 참조할 떄도 원래는 마스크가 3x1인데 단지 masked되서 [1,0,0]으로 해당 픽셀이랑 미래픽셀값인 오른 쪽은 없게 만듬)이기도 하다,

> 여기서 혼동이 생길 수도 있는데, PixelCNN에서 Evaluation과 Inference는 전혀 다른 차원의 문제다. Evaluation도 Label이 있는 데이터를 기준으로 Teacher Forcing 상황을 가정해서 병렬적으로 할 수 있지만, Inference는 Label을 모르는 상태이므로 반드시 한 픽셀 한 픽셀 Sequential하게 만들어 나가게 된다. 즉 병렬처리를 할 수 없는 상황이므로 h와 x는 h x 3 x 1의 차원을 가진 Parameter로 봐야 Trainig 방식과 Inference 방식 간의 혼동을 막을 수 있다.

장황하게 앞에서 설명한 부분이 결국 이 말에 해당된다.

> 이제 Inference시에, 맨 위, 맨 왼쪽 픽셀부터 이러한 방식으로 한 픽셀 한 픽셀 만드는 상황을 생각해보자. 각 픽셀은 상단으로 역삼각형 형태의 Dependency를 갖게 되므로, 우측 하단으로 Context에 반영해야 하지만, 반영하지 못하는 꽤 큰 영역이 생기게 된다. 이런 영역을 Blind Spot이라고 한다. Row LSTM은 이러한 Blind Spot으로 인해 밑에 설명할 Blind Spot이 아예 없는 Diagonal BiLSTM에 비해 높은 NLL을 갖는다.(당연히 높을 수록 안 좋은 Score다.) 다만 더 간단한 연산방식으로 Diagonal BiLSTM에 비하면 더 빠른 속도를 보여준다.

```
Blind Spot 영역 (올바른 표현):
X X X X X X X   ← 이전 행들
 X X X X X X    
  X X X X X     ← Row LSTM은 이 영역의 많은 부분에
   B B B B        직접 접근할 수 없음 (B: Blind Spot)
    X X X      ← 현재 행 바로 위 3픽셀만 직접 접근
     - -       ← LSTM 상태 전파
      O        ← 현재 생성 중인 픽셀
  
```

이런 느낌이라 보면 될 듯 하다.
