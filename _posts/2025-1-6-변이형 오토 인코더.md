---
key:
title: '변이형 오토인코더 공부'
excerpt: '변이형 오토인코더'
tags: [VAE]
---

앞에서 설명한 오토 인코더는 잠재공간을 보다보면 여러 문제점들이 존재한다.

![오토인코더(AutoEncoder) - 공돌이의 수학정리노트 (Angelo's Math Notes)](https://raw.githubusercontent.com/angeloyeo/angeloyeo.github.io/master/pics/2020-10-10-autoencoder/pic4.png)

출처)공돌이의 수학노트

## 오토인코더의 문제점

1. 일부 포인트는 매우 작은 영역에 모여있고, 다른 포인트는 매우 넓은 영역으로 퍼져있다.
2. 포인트 (0,0)에 대해 분포가 대칭이 아니고, 경계가 정해져 있지도 않다.
3. 포인트가 거의 없는 색상 사이에는 간격이 크다. 

그냥 여러 개 나열했지만 간단히 말해 잠재공간이 지멋대로, 규칙없이 포인트가 나열되있다, 우리는 이제 이 잠재공간에서 포인트를 뽑아서 이미지를 생성할건데 포인트를 찝어서 고르고자 할 떄 이러면 디코더가 항상 만족스러운 이미지를 생성하지 못하게 된다, 즉, 안정성이 떨어진다, 왜냐하면 

1. 잠재 공간에서 원본 이미지가 인코딩되지 않은 구멍이 있다, 예를 들어 잠재공간의 가장자리에는 큰 공백이 있는데, 훈련 세트에서 매우 적은 이미지가 여기에 인코딩 되었기 떄문에, 해당 구역에 포인트에 적절한 이미지로 디코딩하지 못할 확률이 높다.

2. 위의 그림을 보면 보라색과 파란색은 그나마 왼쪽 위, 오른쪽 아래에 있다고 해도 그 가운데에 있는 색들은 어디에 있다고 말하기가 매   하다, 즉 포인트의 분포가 정의되있지 않기 떄문에, **잠재 공간에서 랜덤한 포인트를 어떻게 선택해야 하는지 명확하지 않다.** 

   이러한 점은 오토인코더가 다룰 수 있는 차수가 많아질수록, 포인트사이의 간격이 상대적으로 커지므로 더 문제가 뚜렷해진다.

그래서 이러한 문제들을 해결하기 위해서 어떻게 해야할까? 그냥 직관적으로 생각해보면, 숫자 1이라는 이미지가 **해당 영역**에서 뽑을 수 있다는 확실한 보증을 하면 된다. 그러면 그 보증을 한다는건 어떻게 하는 걸까?

## 영역을 보증해주는 변이형 인코더

들어가기 앞서

### 다변량 정규 분포란?

정규분포는 평균과 분산을 이용하여 확률 분포를 나타내는 그래프이다, 1차원의 정규 분포 확률 밀도 함수의 식은 $f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$ 이다, 즉 표준편차라는 $\sigma$와 $\mu$라는 평균을 이용해서 확률분포를 나타낸다, 이건 데이터 $x$ 하나, 1차원의 이야기인데, 즉 예를 들어 **우리나라 평균 신장 분포**가 있을거고 키(신장)이라는 하나의 데이터로 확률분포가 나타난다, 즉 차원이 하나다. 이번엔 **우리나라의 평균 신장에 따른 체중 분포**를 따진다고 해보자, 보통 키가 커짐에 따라 체중도 일반적으로 커지는 경향성을 보인다, 키라는 변수가 체중에 영향을 끼친다고 했을 떄? 그 떄 확률분포를 구하고자 하는게 다변량 정규분포다, 즉 우리나라 사람들의 키의 평균과 표준편차, 체중의 평균과 표준편차, 두 개의 정규분포가 나온다는 의미다.

식으로 나타내면 $f(x) = \frac{1}{(2\pi\sigma^2)^{k/2}} exp(-\frac{1}{2\sigma^2}(x-\mu)^T(x-\mu))$

![img](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/MultivariateNormal.png/270px-MultivariateNormal.png)



여기서 저 2개의 평면에 투사된 두개의 정규분포처럼 다변량 정규분포, 여기서 2차원은 2개의 정규분포가 나온다는 말이다, 근데 키와 체중은 보통 키가 증가할수록 체중도 증가한다는 경향성이 있다, 즉 하나의 변수가 하나의 변수에 영향을 끼치므로 공분산이 있다(영향이 있다), 앞에 배웠던 공분산 행렬은 대각선에 있는 원소들을 제외한 나머지 원소들이 0인지 아닌지에 따라 독립인지 아닌지를 구별했다(대각행렬이면 각 차원에 대해 독립이므로).

![공분산](https://velog.velcdn.com/images/rokky/post/97568c5f-b974-458b-8f6f-c76ba9097ad8/image.png)



즉 대각선에 있는 원소들의 $\sigma$ 는 하나의 입력$x$에 따라 표준편차가 정해지는데, 나머지 원소들은 각각의 입력 $x$에 따라 서로가 영향을 받는 모습을 바로 알 수 있다.

![image-20250105180729372](https://raw.githubusercontent.com/kirity1/blogimg/master/uPic/image-20250105180729372.png)

즉 이런 모습처럼 키와 체중이 서로 영향을 주는 그래프를 볼 수 있다, 그니까 키가 크다고 무조건 체중이 높다는 말이 아니라, 확률적으로 분포가 그렇다는 말이다. 여기서 보통 변이형 오토인코더는 공분산 행렬이 대각행렬인 **등방성 다변량 표준 정규 분포**를 사용한다, 이 말은 대각선에 있는 원소들을 제외한 나머지 원소들은 0이라는 의미로, 이는 각각의 차원 분포들이 각 차원에서 독립적이라는 의미로, 저런 그래프의 경향성이 없이 원이라는 소리다.(즉, 벡터의 각 원소를 독립적인 평균과 분산을 가진 정규 분포에서 샘플링이 가능함)

![image-20250105181329213](https://raw.githubusercontent.com/kirity1/blogimg/master/uPic/image-20250105181329213.png)

(상관 관계가 없는 등방성 공분산일떄의 모습)

즉 평균 벡터가 0이고 공분산 행렬이 단위벡터인 다변량 분포이다.

## 변이형 오토인코더

그래서 앞에 설명한 다변량 정규분포는 무슨 목적으로 설명했냐? 바로 잠재공간의 차원들에 저 정규분포들을 도입한다는 아이디어가 변이형 오토인코더이다. 잠재공간의 차수가 2차원 이상으로 높아지는 거때문에 다변량 정규분포(여기선 말했듯이, 다변량 표준정규분포)를 이용한다는건 알겠지만, 왜 쓰는걸까?

앞서 오토인코더의 문제점을 짚을 떄, **특정 영역에 있다는 보증**이 있게 해야 한다고 했다.

 ![VAE: Variational Autoencoders — How to Employ Neural Networks to Generate  New Images | by Saul Dobilas | Towards Data Science](https://miro.medium.com/v2/resize:fit:1400/1*VN5ILV7z8mHM3oUS_VDqzg.png)

이런 식으로, 어떤 하나의 포인트로 두는게 아니라 분홍색 영역, 초록색 영역, 노랑색 영역으로 각각의 영역을 다변량 정규분포로 다뤄 (잠재공간이 다차원이기 떄문에) 잠재공간의 각 차원의 평균과 정규분포를 다뤄 **확률분포라는 형태의 영역으로 잠재공간의 모호함을 해결**하고자 하는거다. **각 포인트가 차원이라는게 아니다, 잠재공간이 다차원인거고, 포인트들은 거기에 따라 다변량정규분포가 그려지는거다. 즉 각 포인트(그리고 거기서 한 점을 찍은 이미지)는 전체 잠재 공간에서 하나의 다변량 정규분포로 표현된다는 거다.**

즉 인코더를 거쳐 잠재 공간의 다변량 정규 분포를 정의하는 다음 2개의 벡터로 인코딩하면 된다.

z_mean : 이 분포의 평균 벡터

z_log_var : 차원별 분산의 로그 값 (보통 로그로 바꿔놔야 계산이 편해진다)

평균 벡터 μ = [μ₁, μ₂, ..., μₖ]

분산 벡터 σ² = [σ₁², σ₂², ..., σₖ²]

예시 (k=4 차원일 때):

입력 이미지 → 인코더 →
μ = [1.2, -0.5, 0.8, 0.3]     # 4차원 평균 벡터
σ² = [0.1, 0.2, 0.15, 0.1]    # 4차원 분산 벡터

각 차원마다 독립적인 평균과 분산을 가짐

실제 잠재 벡터 z는 이 평균과 분산을 사용해 샘플링됨

 z = μ + σ * ε    (ε ~ N(0,1)) (각 차원에서)

### 다변량 표준정규분포인 이유

#### 수학적 단순성과 계산 효율성:

독립적인 차원들은 계산이 더 간단함

샘플링이 쉬움 (각 차원별로 독립적으로 샘플링 가능)

KL Divergence 계산이 단순화됨

#### 연속성과 완전성:

표준정규분포는 잠재 공간을 빈틈없이 채움

가까운 점들은 비슷한 특성을 가질 가능성이 높음

부드러운 보간(interpolation)이 가능

#### 정규화(Regularization) 효과:

잠재 변수들이 너무 멀리 퍼지는 것을 방지

오버피팅 감소

더 의미있는 특성 학습 유도

하지만 실제로는 잠재 변수들 간의 상관관계가 있을 수 있음.

이를 해결하기 위한 변형 모델들이 존재:

β-VAE: 잠재 변수의 독립성을 더 강화

VQ-VAE: 이산적인 잠재 공간 사용

Flow-based 모델: 더 복잡한 분포 학습

다음은 이 인코더를 실제로 구현하는 방법을 다루겠다.
