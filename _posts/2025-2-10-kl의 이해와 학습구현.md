---
key:
title: '변이형 오토인코더 코드 만들어보기'
excerpt: '변이형 오토인코더'
tags: [VAE]
---

Epoch [1/5], Loss: 0.2816, BCE: 0.0056, KL: 0.0001
Epoch [2/5], Loss: 0.2506, BCE: 0.0050, KL: 0.0000
Epoch [3/5], Loss: 0.2474, BCE: 0.0049, KL: 0.0000
Epoch [4/5], Loss: 0.2466, BCE: 0.0049, KL: 0.0000
Epoch [5/5], Loss: 0.2463, BCE: 0.0049, KL: 0.0000

### 1. Loss 값이 낮다고 해서 무조건 과적합(overfitting)이 발생한 것은 아닙니다

과적합(Overfitting)은 보통 학습 데이터에서는 매우 낮은 loss가 나오지만, 검증이나 테스트 데이터에서는 성능이 떨어지는 현상을 뜻합니다.

현재의 경우 학습 루프의 출력으로 나타난 loss 값들이 일정하게 낮게 유지되고 있는 것은 학습이 어느 정도 안정된 상태임을 의미할 수 있습니다.

\---

### 2. 생성된 이미지들이 모두 비슷하게 나오는 이유

Posterior Collapse (후방 붕괴)

VAE에서는 인코더가 입력을 잠재 공간의 분포(평균과 로그 분산)로 매핑하고, 디코더가 이 정보를 이용해 이미지를 재구성합니다.

하지만, 만약 KL divergence 값이 거의 0에 가까워진다면, 이는 인코더가 입력 데이터를 기준으로 별도의 분포 정보를 생성하지 않고 기본적인 표준 정규분포에 가깝게 매핑되고 있다는 뜻입니다.

이런 경우 디코더는 잠재 변수의 영향을 거의 무시하게 되어, 다양한 latent 입력에도 동일하거나 비슷한 이미지를 생성하게 됩니다.

이는 posterior collapse라고 부르며, 잠재 공간이 제대로 활용되지 않아 다양성이 떨어지는 현상을 설명합니다