---
key:
title: 'pixelcnn 이해 - 4'
excerpt: 'pixelcnn'
tags: [컴퓨터비전]
---

## Diagonal BiLSTM

![img](https://github.com/demul/basic_idea/raw/master/Understanding%20PixelCNN/images/pixelrnn8.png)

> Diagonal BiLSTM은, 한 픽셀이 자신 바로 위의 한 픽셀과, 자신 왼쪽의 한 픽셀로 부터 state를 전달받는 과정을 효율적으로 병렬화하기 위해서 Feature Map을 Skew하는 트릭을 사용한다. 이렇게 하면 1 x 2 모양 Convolution 커널하나로 왼쪽, 위 픽셀로 부터 현재 픽셀로 State를 전달할 수 있다. Diagonal BiLSTM에서는 이 1 x 2 Non-Masked Convolution 커널이 State-to-State 커널이 된다. 또한 자기 자신으로부터도 State를 전달받아야 하므로 1 x 1 Masked Convolution을 사용하는데 이게 Input-to-State 커널이 된다.

Row LSTM이 '행' 단위로 병렬화를 시도했다면, Diagonal BiLSTM은 더 촘촘하게 '대각선' 방향으로 픽셀 간의 관계를 학습하려 한다. 하지만 여기서 큰 난관에 봉착한다.

우리가 통상적으로 이미지를 처리할 때(열 단위 병렬화 시도 시), 내 **위쪽 픽셀**은 나와 **같은 열**에 존재한다. 즉, 내가 계산되려면 위쪽이 먼저 계산되어야 하는데, 같은 라인에 서 있으니 동시에 계산(병렬화) 할 수가 없는 '순서 꼬임' 문제가 발생한다.

이걸 해결하기 위해 등장한 발상이 바로 **Feature Map Skewing(비틀기)**이다.

#### 1. Skew : 의존성을 한쪽으로 몰아넣기

1. **입력 변환 (Skew):** 원본 이미지의 각 행을 이전 행보다 한 칸씩 오른쪽으로 민다.
2. **결과:** 이렇게 하면 원래 내 머리 위에 있던(같은 열, 위쪽) 픽셀이 내 왼쪽 대각선(이전 열)으로 이동하게 된다.
3. **병렬 처리:** 이제 내게 필요한 정보(왼쪽, 위쪽)가 모두 **'이전 열'**에 존재하게 된다. 더 이상 같은 열에서 눈치 볼 필요 없이, 현재 열을 한 번에 병렬로 계산할 수 있다.

#### 2. 두 가지 커널의 역할

이제 비틀어진(Skewed) 맵 위에서 컨볼루션을 돌리기 위해 두 가지 커널을 사용한다. 각각의 역할은 명확하다.

- **1x2 State-to-State 커널 (s-s): **
  - 이 커널은 `[1, 2]` 사이즈를 가진다. 즉, 현재 위치의 바로 왼쪽 옆에 있는 두 픽셀을 본다.
  - Skew 된 공간에서의 '왼쪽 두 픽셀'은, 원본 공간으로 치면 **'내 왼쪽 픽셀'**과 **'내 위쪽 픽셀'**에 해당한다.
  - 즉, 이 커널은 **나에게 영향을 주는 과거의 의존적인 픽셀들(Context)**을 한 번에 긁어오는 역할을 한다. (Non-Masked)
- **1x1 Input-to-State 커널 (i-s): **
  - 이 커널은 `[1, 1]` 사이즈다.
  - 바로 **지금 학습하고자 하는 현재 픽셀(Input)**의 값을 처리한다.
  - 자기 자신의 정보를 받아들여야 하므로 Masked Convolution(Mask B)이 적용된다.

#### 3. 전체 흐름 요약

결국 Diagonal BiLSTM의 처리 과정은 **[비틀기 $\rightarrow$ 계산 $\rightarrow$ 원복]**의 3단계다.

1. **Skew:** 이미지를 비틀어서 대각선 의존성을 수직(열) 의존성으로 바꾼다.
2. **Conv:**
   - `1x2 커널`로 이전 열에 몰아넣은 의존성 픽셀들(왼쪽, 위)을 챙기고,
   - `1x1 커널`로 현재 픽셀(나)을 챙겨서 병렬 연산한다.
3. **Unskew:** 계산이 끝나면 다시 왼쪽으로 밀어서 원래 이미지 형태로 복원한다.

이 트릭 덕분에 Diagonal BiLSTM은 복잡한 대각선 의존성을 가지면서도, 효율적인 병렬 연산이 가능해져 **전체적인 수용 영역(Receptive Field)을 Blind Spot 없이** 확보할 수 있게 된다. 

시각적으로 보자면

```
처리 순서 (왼쪽 위부터 오른쪽 아래로):
1  2  3  4
5  6  7  8
9  10 11 12
13 14 15 16
```

- 여기서 **픽셀 11**을 계산하려면 두 가지 정보가 필요하다.

  - **픽셀 7 (위쪽):** 이전 행의 정보
  - **픽셀 10 (왼쪽):** 같은 행의 이전 정보

  문제점:

  우리가 만약 '열(Column)' 단위로 계산을 하려고 한다면, 11번 픽셀이 있는 **3번째 열(3, 7, 11, 15)**을 동시에 계산하고 싶을 것이다.

  하지만 11번을 계산하려면 같은 열에 있는 7번이 먼저 계산되어야 한다. (7 $\rightarrow$ 11 순서 강제). 즉, 같은 열 내부에서 의존성이 생겨버려 병렬 처리가 불가능하다.

```
Skew 변환 후:
1 2 3 4
  5 6 7 8
    9 10 11 12
      13 14 15 16
```

이미지를 행마다 한 칸씩 밀어버렸다(Skew). 이제 픽셀들의 위치 관계가 극적으로 변한다.

- **픽셀 11의 위치:** 3번째 열에서 더 뒤쪽 열로 밀려났다.
- **픽셀 7 (의존 타겟 1):** 11번보다 **이전 열**에 위치한다.
- **픽셀 10 (의존 타겟 2):** 11번보다 **이전 열**에 위치한다.

**해결책:** 이제 픽셀 11을 계산하기 위해 필요한 7과 10은 모두 **"이미 계산이 끝난 이전 열"**에 존재한다. 더 놀라운 점은, 원래 11번과 같은 열에 있어서 발목을 잡던 **3, 7, 15번 픽셀들이 이제는 모두 서로 다른 열로 흩어졌거나, 의존 관계가 없는 위치로 갔다**는 것이다.

#### 3.  병렬화

이 트릭의 핵심은 이것이다.

> **"전체적인 진행은 열(Column) 단위로 순차적으로 가지만, 현재 처리 중인 열(Column) 내부의 픽셀들은 서로 남남이다."**

변환된 맵 상에서 같은 열에 위치한 픽셀들은 서로의 계산 결과가 필요 없다. 모두 "바로 앞 열"만 쳐다보고 있으면 된다. 따라서 **한 열에 있는 모든 픽셀을 동시에(병렬로) 계산**할 수 있게 된다. 이것이 Diagonal BiLSTM이 복잡한 의존성을 가지면서도 속도를 확보한 비결이다.

즉 열은 순차적으로 처리되더라도 그 열 안에는 병렬적으로 처리가 가능해진다는 말이다.

> 여기서 1 x 1 커널인데 Masked Convolution 커널이라는게 도대체 무슨 뜻인지 헷갈릴 수 있다. 하지만 위 Masked Convolution 설명을 다시 보면 Masked Convolution은 채널간에도 Mask를 적용하므로, 1 x 1이라서 x축, y축 차원으로는 Masking이 없지만 채널 차원으로 Masking이 있는 Convolution이라고 생각하면 쉽게 이해할 수 있다.

여기서 말 그대로라서 이해가 어려운 부분은 없지만 한 가지 참고해야 할 건 채널간의 masking, PixelCNN과 BiLSTM의 1×1 Masked Convolution은 R - f(R) 같은 대응이 아닌 

- R 출력: "R 입력만 사용"

- G 출력: "R과 G 입력을 혼합"

- B 출력: "R, G, B 모두 혼합"

이런 느낌이다

![PixelCNN](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAP8AAADGCAMAAAAqo6adAAABBVBMVEUAAAD4zszV6NTa6Pz709Hf7P8cK0D8z8+/vpnE3sDa7NSFoc6vxefJeHUfMEaZwYZ8pmWLps/XiYbb7dusVVJqh7K316zjop+nzpZDExAsQh2ctt2OQT6TQ0BOJCJmjFCHPjtwMzE/HRs7US5VJyVBWjMzFxZ6NzUUCQkOEws8GxqAOjckERBIIR8rExMaDAsQFw1lLiy8XVmnlmybxIFxkcWxoXafzI6mw5KzoLKhsdItFQycR0EAAAqKODaiQkGkVkidY0yOiVaGrWK5U1EdOR6MomIkMht3Vj+BlFpcfkgxDhOLrGaBcExyc0k1SipZHx3AUk07MB1ok09IaDQPFBuSf1dJLfI8AAAD1klEQVR4nO2dCVPTQBSA6wkIKAgqSpImERJom3LI4YGgtIriff7/n+KWFknbTZrskE55/b4ZhpJ0Z/Llvd23u22G0vasGc927hmxsztvxvTdUhHM3jRjcmrBiDvTt8yYuV2Q/zUTJianrhuh/G+YgD/++OOPP/74448//vjjjz/++OOPP/74448//vjjjz/++OOPP/74448//vjjjz/++OOPP/74448//vjjjz/++I+j/3Cf/1oYsee/tu+bsbe/lMjz5FNL+7vLOl6c8VJ7rs18Mc//XTqvVuyDtPOvtUcPj968PW58y91u1PCqR81mmL/du+P3jcbcyeVf0JDxDprNZi13s/qHj41G47SACxo2vtVMTX9tG8/6VDr+3Fgt4oKGi2/XFr18TTYsLyqVyl++zm0Wc01DJLJVF4jytPC37FZ3Ka+WTq5++kfWRr4Gdbd9t04FpH4r+fPpB6EbtH6vy9B37Fxvr4TVoP1Khr5v56l7NTf0Oy/LIvRzRT/yrPr5axn6kZU9+jUrViOE6GePvu+5F7dqXYa+Y2V9Z3DR71tIGfoyFr6gGgaxP6VEP2PyR55b7zogQz9j4VOjnt99RIZ+tuiritd7l4ToW2uD31S3+ldFMvQje7C+munWe4+tl58Wcj1DZmVw8vv/5/lxpER/0NCnVrgVzeExib7TP+qdIST6A7Y76vaWfi9IRvQHFL4odPW3R8rQlzrnV/N8Xb9vMQbJr+b5fRWvwxhE3+md58cRH3016vlJ56QMfcmFT1W8lH4hJvkTJr1B3xqvGyHJnzDn96vV1OngppToaw9H1f5VTjcyou9oO7jKfM0qJ46Yvq856MT3dBOQoa/b7kiveB2E6PcXPjXPH7wFsllO+27PlaE/+Sv69X0vQqLfm/wVN8yy9ys0+o5mX0+LlOh3Fb7A3sqS+QqJ0VcVL+NnXmLqfqzvB3b6PD+ODP34J7xqppvhM4828oa+KHlvR4OU6J8HvDJwnh9nXVj0V7z0FW4vMqJ/PvRlr3gdREVfzXbytRM19OXr92cISv7I9XJ+s1dM9F31E2Za5XQjJPrumhr18ma+oMLneNW8mV8Sk/zOgUnsS1ep8EWPk/n+4zDx3M8nKfz6nXzuril/CvHffmTG3tJDM6ZnzFgeqf9/ODE5tWD6/O9IPf/K88/4448//vjjjz/++OOPP/74448//vjjjz/++OOPP/74448//vjjjz/++OOPP/74448//vjjjz/++OOPP/7444//6PoP9/8fjtrzX4uG/J0zo/HAlGL8AQAAAAAAAAAAAAAAAEAM/wDOJ1QklBmSngAAAABJRU5ErkJggg==)

왜 저렇냐면 

### 1x1 Masked Convolution:

우리가 흔히 아는 1x1 Convolution은 모든 채널의 정보를 섞어서(Linear Combination) 새로운 특징을 만들어낸다. 하지만 PixelCNN에서는 이 '섞임'조차 함부로 허용해선 안 된다. 왜냐하면 **색상(Color) 정보끼리도 인과관계(순서)가 존재하기 때문이다.**

#### 1. R $\rightarrow$ G $\rightarrow$ B의 인과관계

픽셀 하나를 생성할 때도 RGB 값을 동시에 뱉는 게 아니다. 이 안에서도 미세한 자기회귀(Auto-regressive)가 돌아간다.

$$p(x_i) = p(x_{i,R}) \cdot p(x_{i,G} | x_{i,R}) \cdot p(x_{i,B} | x_{i,R}, x_{i,G})$$

즉, 모델은 다음과 같은 순서로 상상을 구체화한다.

1. **Red:** 이전 픽셀들의 문맥만 보고 결정
2. **Green:** 문맥 + 방금 정한 **Red**를 보고 결정
3. **Blue:** 문맥 + 방금 정한 **Red, Green**을 보고 결정

#### 2. 채널 마스킹 (Masking the Weight Matrix)

이 순서를 지키기 위해 1x1 커널의 가중치 행렬(Weight Matrix)에 마스크를 씌운다. 공간적으로는 1픽셀이지만, 내부적으로 채널 간의 연결을 끊어버리는 것이다.

대충 이런 듯 하다. 일단 이렇게 학습할 떈 병렬처리를 하는데

> 이제 Inference시에, 맨 위, 맨 왼쪽 픽셀부터 이러한 방식으로 한 픽셀 한 픽셀 만드는 상황을 생각해보자. 각 픽셀은 자신을 기준으로 -90º ~ 0º 범위에 있는 모든 픽셀에 Dependency를 갖게 된다. 그러나, 현재 행을 제외한 0º ~ 90º 범위에 있는 픽셀들은 Dependency를 가져야 하나 여전히 갖지 못한 Blind Spot이 된다. 이를 해결하기 위해 간단한 트릭이 적용된다.
>
> 오른쪽->왼쪽 Hidden State Map(0º ~ 90º)을 왼쪽->오른쪽 Hidden State Map(-90º ~ 0º)에 간편하게 더해주기 위해서, Figure 3과 같은 방식으로 Parallelization 하되(이 경우 왼쪽으로 Skew) 아웃풋 맵을 전부 한칸씩 밑으로 내려서, 왼쪽->오른쪽 Hidden state에 더한다. 만약 한칸 씩 밑으로 안 내린다면 해당 픽셀이 미래 정보(자기와 같은 열 오른쪽에 있는)를 보게된다.
>
> 이와 같은 방법으로 두 Hidden State Map들을 더하면 Blind Spot이 아예 없는 것을 알 수 있다. Diagonal BiLSTM은 이러한 특성으로 인해 이 논문에 소개된 모델들 중 가장 낮은 NLL과 가장 느린 속도를 보여준다.

생성 할 떄는 왼쪽으로 skew하여 제한적 병렬을 할 수도 있다고 하는데 내용이 길기 떄문에 생략한다.

![img](https://github.com/demul/basic_idea/raw/master/Understanding%20PixelCNN/images/pixelrnn9.png)

> LSTM Gate를 사용하지 않고도 각 픽셀이 좌상단에 Dependency를 갖게 할 수 있는 방법으로, PixelCNN이 있다. 위 그림에서 보는 것처럼 Masked Convolution 커널을 중첩시키는 것 만으로도 이를 구현할 수 있다. 다만 Dependency Filed가 중첩된 Layer수에 따라 선형적으로 증가한다는 점(즉 충분히 Convolution 커널을 쌓지 않으면 Dependency Filed 크기가 작다는 점), LSTM Gates와 같은 Multiplicative Unit이 없어 모델의 표현력이 떨어진다는 점, 그리고 Row LSTM처럼 Blind Spot이 존재한다는 점 등의 한계로 인해 이 논문에 소개된 세 모델 중 가장 높은 NLL을 보여준다. 다만 느리기로 악명높은 LSTM Unit을 아예 사용하지 않기 때문에 가장 빠른 속도를 가지고 있다.

이게 앞에서 말한 lstm과 pixelCNN의 차이점이다

