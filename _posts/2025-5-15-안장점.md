---
key:
title: '오차함수 미분에서 나오는 안장점'
excerpt: 'deeplearning'
tags: [deeplearning]
---

# 비볼록 함수의 또 다른 복병: 안장점 (Saddle Points) 파헤치기

이전 글에서는 비볼록 손실 함수가 가진 여러 지역 최솟값(local minima) 때문에 최적의 해를 찾기 어렵다는 점을 살펴보았다. 하지만 비볼록 함수의 복잡한 지형에는 지역 최솟값 외에도 최적화를 방해하는 또 다른 장애물, 바로 **안장점(saddle point)**이 존재한다.

## 1. 안장점이란 무엇인가? 임계점과 페르마 정리

먼저 **임계점(critical point)**이라는 개념을 이해할 필요가 있다. 함수 $f$가 미분 가능할 때, 그래디언트 $\nabla f$가 0이 되는 지점, 즉 $\nabla f = \mathbf{0}$인 지점을 임계점이라고 한다. **페르마의 정리(Fermat's theorem on critical points)**에 따르면, 만약 어떤 함수가 특정 지점에서 지역 극값(local extremum, 즉 지역 최솟값 또는 지역 최댓값)을 가진다면, 그 지점은 반드시 임계점이어야 한다 (즉, 그 지점에서 그래디언트는 0이다).

그렇기에 오목한 함수나 볼록한 함수에는 반드시 극값이 하나는 있어야한다.

![image-20250513230825618](https://raw.githubusercontent.com/kirity1/blogimg/master/uPic/image-20250513230825618.png)

안장점 역시 이 임계점의 한 종류이다. 그림 6.4a의 손실 함수 등고선에서 파란색 십자(+)로 표시된 지점이 바로 안장점의 한 예이다. 안장점은 다음과 같은 독특한 특징을 가진다:

1.  **그래디언트(Gradient)는 0이다**: 마치 지역 최솟값이나 최댓값처럼, 안장점에서도 함수의 순간적인 기울기, 즉 그래디언트는 0이다.
2.  **엇갈린 곡률**: 하지만 안장점은 최솟값이나 최댓값과는 다르다. 안장점에서는 어떤 방향으로 움직이면 함수 값이 증가하고(마치 언덕을 오르듯), 동시에 다른 어떤 방향으로 움직이면 함수 값이 감소한다(마치 계곡으로 내려가듯). 이름처럼 말의 안장과 비슷한 형태를 띤다.

안장점을 시각화 해보자

```py
import matplotlib.pyplot as plt
import numpy as np

fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111, projection='3d')

# 데이터 생성
x = np.arange(-5, 5, 0.25)
y = np.arange(-5, 5, 0.25)
X, Y = np.meshgrid(x, y)
Z = X**2 - Y**2  # 안장점 함수 f(x,y) = x^2 - y^2

# 3D 표면 플롯
surf = ax.plot_surface(X, Y, Z, cmap='viridis', edgecolor='none', alpha=0.8)

# 안장점 표시 (0,0,0)
ax.scatter([0], [0], [0], color='red', s=100, label='Saddle Point (0,0,0)')

# 축 레이블 설정
ax.set_xlabel('X axis')
ax.set_ylabel('Y axis')
ax.set_zlabel('Z axis (f(x,y))')
ax.set_title('3D Visualization of a Saddle Point: $f(x,y) = x^2 - y^2$')

# 컬러바 추가
fig.colorbar(surf, shrink=0.5, aspect=5)

# 범례 표시
ax.legend()

# 그래프 보기 각도 조절 (선택 사항)
# ax.view_init(elev=20, azim=-35)

plt.show()

print("-------------------------------------------------------------------")
print("안장점 시각화 설명:")
print(" - 빨간 점: (0,0,0) 지점의 안장점을 나타냅니다.")
print(" - X축을 따라서는 Z값이 증가하는 포물선 (x^2) 형태를 보입니다 (아래로 오목).")
print(" - Y축을 따라서는 Z값이 감소하는 포물선 (-y^2) 형태를 보입니다 (위로 볼록).")
print(" - 안장점 (0,0) 주변은 상대적으로 평평하게 보일 수 있으며,")
print("   이로 인해 경사 하강법이 느리게 진행되거나 잘못 수렴할 수 있습니다.")
print("-------------------------------------------------------------------") 
```

![image-20250513231115623](https://raw.githubusercontent.com/kirity1/blogimg/master/uPic/image-20250513231115623.png)



우리가 시각화를 위해 사용했던 대표적인 안장점 함수는 $f(x,y) = x^2 - y^2$ 이다. 이 함수의 그래디언트는 다음과 같다:
$$ \nabla f(x,y) = \left[ \frac{\partial f}{\partial x}, \frac{\partial f}{\partial y} \right] = [2x, -2y] $$
이 식에서 볼 수 있듯이, $(0,0)$ 지점에서 그래디언트는 $[2(0), -2(0)] = [0,0]$ 이 된다.

## 2. 그래디언트가 0이 되는 이유: 극값과 안장점의 차이

그렇다면 왜 지역 최솟값/최댓값과 안장점 모두에서 그래디언트가 0이 될까? 그 근본적인 원리는 각 지점에서의 함수의 형태에 있다.

*   **지역 최솟값 (또는 전역 최솟값)**:
    이 지점에서는 모든 방향으로 함수가 **아래로 볼록(convex downwards)**한 형태를 띤다. 예를 들어 $f(x,y) = x^2 + y^2$의 $(0,0)$ 지점을 생각해보자. x축을 따라서도 아래로 볼록하고, y축을 따라서도 아래로 볼록하며, 그 외 어떤 방향을 따라서도 아래로 볼록하다. 각 방향에서 봤을 때 그 지점이 "바닥"이므로, 각 방향으로의 편미분 값 (기울기)이 0이 된다. 따라서 전체 그래디언트 벡터가 $\mathbf{0}$이 된다. (지역 최댓값은 모든 방향으로 위로 오목(concave upwards)하다.)

*   **안장점**:
    이 지점에서는 방향에 따라 곡률이 다르다. 우리가 논의했던 것처럼, 안장점은 **"한 방향으로는 아래로 볼록(최솟값의 특징)하고, 다른 방향으로는 위로 오목(최댓값의 특징)한 형태가 겹쳐진 것"**으로 이해할 수 있다.
    $f(x,y) = x^2 - y^2$의 $(0,0)$ 지점을 다시 예로 들면:
    *   **x축 방향 (y=0 고정)**: 함수는 $f(x,0) = x^2$가 된다. 이는 $x=0$에서 명백히 아래로 볼록한 최솟값을 가진다. 따라서 이 방향으로의 편미분 $\frac{\partial f}{\partial x}$는 $x=0$에서 0이다. ($2x \big|_{x=0} = 0$)
    *   **y축 방향 (x=0 고정)**: 함수는 $f(0,y) = -y^2$가 된다. 이는 $y=0$에서 명백히 위로 오목한 최댓값을 가진다. 따라서 이 방향으로의 편미분 $\frac{\partial f}{\partial y}$는 $y=0$에서 0이다. ($-2y \big|_{y=0} = 0$)
    결국, 각 축 방향에서 "극값"의 성질을 가지기 때문에 각 편미분 값이 0이 되고, 결과적으로 전체 그래디언트 벡터 $\nabla f = [\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}]$가 $(0,0)$에서 $[0,0]$이 되는 것이다.

## 3. 안장점, 왜 문제가 될까? "내리막길이 있는데?"

여기서 한 가지 직관적인 의문이 생길 수 있다. "안장점에서 어떤 방향으로는 함수 값이 감소한다면, 즉 내리막길이 존재한다면, 경사 하강법이 그 길을 따라 내려가면 되는 것 아닌가? 왜 안장점이 문제가 되는 거지?"

실제로 안장점 *자체*가 아닌, 그 *근처*에 있다면 일단 미분값이 0이 아니긴 해서 경사 하강법은 이론적으로 손실이 감소하는 방향으로 움직여 안장점에서 벗어날 수 있다. 그러나 문제는 그렇게 간단하지 않다. 안장점이 최적화에 어려움을 주는 주된 이유는 다음과 같다.

### 3.1. 그래디언트의 "방향" vs. "크기"

안장점 근처에서는 분명히 손실 함수 값이 줄어드는 "내리막길" 방향이 존재한다. 하지만 진짜 문제는 그 내리막길의 **경사가 매우 완만하다는 점**, 즉 그래디언트 벡터의 **크기(magnitude)**가 극도로 작다는 데 있다.

경사 하강법은 다음과 같은 규칙으로 파라미터를 업데이트한다:
`새로운 위치 = 현재 위치 - 학습률 * 그래디언트`

그래디언트의 크기가 매우 작으면, 학습률을 곱해도 파라미터가 움직이는 거리가 아주 미미해진다.

즉 그래디언트 벡터의 '크기(magnitude)'가 (0.002)2+(−0.002)2≈0.00028로 매우 작다.

### 3.2. 안장점 근처에서의 움직임: "평평함"과의 싸움

*   **매우 느린 진행 (Slow Progress)**: 안장점 근처는 표면이 매우 평탄하기 때문에, 그래디언트의 크기가 작아 학습이 엄청나게 느리게 진행될 수 있다. 마치 넓고 거의 수평에 가까운 고원에서 아주 희미한 내리막길을 찾아 아주 조금씩 움직이는 것과 같다. (앞서 우리가 `matplotlib`을 이용해 $f(x,y) = x^2 - y^2$ 함수를 3D로 시각화했을 때, $(0,0)$ 주변이 다른 영역에 비해 상대적으로 평탄해 보였던 것을 기억할 것이다.)
*   **조기 종료 (Premature Convergence)**: 많은 최적화 알고리즘은 그래디언트의 크기가 특정 임계값보다 작아지면 학습이 충분히 이루어졌다고 (수렴했다고) 판단하고 멈춘다. 안장점 근처는 그래디언트가 워낙 작기 때문에, 알고리즘이 실제 전역 최솟값이나 의미 있는 지역 최솟값에 도달하기 한참 전에, "이 정도면 평지에 도달했으니 학습을 종료해도 되겠다"고 오판하여 안장점 근처에서 잘못 멈출 수 있다. "it’s hard to be sure that training hasn’t converged"라는 문구가 바로 이 상황을 지적한다. 겉보기에는 학습이 끝난 것처럼 보이지만, 실제로는 좋지 않은 안장점 부근에 머물러 있는 것이다.

*   **안장점 바로 그 지점** ($(0,0)$)에서는 $\nabla f = [0,0]$ 이므로 모든 방향으로의 힘(기울기)이 정확히 0이 되어 (완벽히 상쇄되어) 멈춘다.
*   **안장점 근처**에서는 내려갈 방향이 있지만, 그 방향으로의 경사 자체가 너무 완만해서 (그래디언트 벡터의 전체 크기가 너무 작아서) 움직임이 매우 둔화되거나 멈춘 것처럼 보이게 된다.

## 4. 결론

안장점은 비볼록 손실 함수에서 최적화를 어렵게 만드는 또 다른 요인이다. 그래디언트가 0이 되는 지점이지만 최솟값은 아니며, 주변의 평탄한 지형 때문에 경사 하강법이 매우 느리게 진행되거나 조기에 잘못된 지점에서 멈출 위험이 있다. 우리가 함께 코드를 작성하여 시각화해 보았듯이, 안장점의 형태와 그 주변의 평탄함을 직접 눈으로 확인하는 것은 이러한 현상을 이해하는 데 큰 도움이 된다. 이러한 안장점의 특성을 이해하는 것은 더 나은 최적화 알고리즘을 설계하고 딥러닝 모델의 학습 과정을 분석하는 데 중요하다.