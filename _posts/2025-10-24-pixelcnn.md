---
key:
title: 'pixelcnn 이해 - 2'
excerpt: 'pixelcnn'
tags: [컴퓨터비전]
---

> Masked Convolution은 위 그림과 같이 자신의 왼쪽과 위쪽을 제외한 나머지 영역의 Weight를 0으로 만든 Convolution을 의미한다. 즉 Dependency의 방향을 왼쪽, 위로 한정하기 위해 사용한다. Mask A는 현재 연산중인 픽셀의 채널을 Context에 포함하지 않는 방식이고, Mask B는 현재 연산중인 픽셀의 채널을 포함하는 방식이다. 현재 연산중인 픽셀과의 Dependency는 최초에 한번 끊어주면 되므로 Table 1에서 보는 것처럼 Mask A는 최초에 한번만 적용된다.

![img](https://github.com/demul/basic_idea/raw/master/Understanding%20PixelCNN/images/pixelrnn7.png)

여기서 "최초의 한번만 끊어주면 되므로 mask A를 최초에 한번만 적용시킨다"는 말은 pixelCNN에서 첫 입력값(이미지)를 그대로 픽셀값으로 쓰면 치팅 효과가 발생하기 떄문에, 즉 이 마스크를 적용하면 이후 레이어의 특징 맵에는 이미 현재 픽셀의 원본 정보도 없고 그 이후에 mask B를 사용하더라도 원본 정보가 없기 떄문에 자기회귀를 구현 하기도 가능하다, 그리고 여기서 pixelCNN은 lstm처럼 셀을 여러차례 타입스텝으로 도는게 아니라 여러 레이어로 이루어진 신경망이 생성한 부분적 출력(현재까지 생성된 이미지)을 다시 입력으로 사용하여 반복적으로 동작하는(생성할 떄, 학습 할 떄는 병렬적으로 한번에 함) 자기회귀(auto-regressive) 모델 둘의 구조(아키텍쳐)가 다르다. lstm과 비교하자면

- ### LSTM과의 비교: 시간(Time) vs 깊이(Depth)

  PixelCNN은 LSTM처럼 셀을 여러 차례 타임스텝으로 도는 게 아니라, 여러 레이어로 이루어진 신경망이 생성한 부분적 출력(현재까지 생성된 이미지)을 다시 입력으로 사용하여 반복적으로 동작하는 구조다.

  **1. 구조적 차이**

  - **LSTM (Time-domain):** 시간적 차원으로 반복 실행되는 단일 셀 구조다.
    - 각 시간 단계(Time step)마다 **동일한 가중치(Shared Weights)**를 사용한다.
    - "첫 번째로 돌 때"는 시간 단계 측면에서의 첫 단계를 의미한다.
  - **PixelCNN (Depth-domain):** 여러 합성곱 레이어가 깊이 방향으로 쌓인 구조다.
    - 각 레이어는 서로 **다른 가중치와 기능**을 가진다.
    - "첫 레이어"는 네트워크 깊이 측면에서의 첫 번째 레이어를 의미한다.

  **2. 공통점 (자기회귀 모델의 특성)**

  - **조건부 확률 모델링:** $p(x_t | x_1, x_2, ..., x_{t-1})$
  - **순차적 생성:** 이전에 생성된 값들을 조건으로 다음 값을 생성한다.
  - **목표:** 이미지를 픽셀 단위로 순차적으로 생성하며, 현재 픽셀은 이전 픽셀에만 의존한다.

  **3. 생성 과정(Inference)의 차이**

  실제로 이미지를 생성할 때의 프로세스를 비교해보면 차이가 명확하다.

  **LSTM의 생성 과정**

  1. 첫 픽셀 생성
  2. 그 픽셀을 LSTM 셀의 입력으로 사용
  3. 두 번째 픽셀 생성
  4. 첫 번째와 두 번째 픽셀을 바탕으로 세 번째 픽셀 생성
  5. 이 과정을 반복...
     - $\rightarrow$ **동일한 셀의 순차적 실행을 통한 자기회귀 구현 (시간적 전개)**

  **PixelCNN의 생성 과정**

  1. 빈 이미지로 시작
  2. 첫 픽셀 위치의 확률 분포 계산 $\rightarrow$ 첫 픽셀 생성
  3. 첫 픽셀이 채워진 이미지를 **전체 네트워크**에 통과 $\rightarrow$ 두 번째 픽셀 생성
  4. 두 픽셀(첫 번째, 두 번째)이 채워진 이미지를 **전체 네트워크**에 통과 $\rightarrow$ 세 번째 픽셀 생성
  5. 이 과정을 반복...
     - $\rightarrow$ **마스킹된 합성곱과 깊은 네트워크를 통한 자기회귀 구현 (공간적 전개)**


정확하게 pixelCNN이 도는 걸 이해하자면 예를 들어 12번쨰 픽셀을 생성한다고 하자면

```
생성 순서:
[ 1,  2,  3,  4]
[ 5,  6,  7,  8]
[ 9, 10, 11, 12]

12번째 픽셀 생성 시 네트워크 입력:
[ A,  B,  C,  D]  ← 이미 생성된 픽셀들 (1-11번)
[ E,  F,  G,  H]
[ I,  J,  K,  0]  ← 12번 위치는 아직 비어 있음(0)
                    (이 위치의 값을 예측하기 위함)
```

1. **초기 상태:** 빈 이미지(모든 픽셀이 0)로 시작한다.
2. **1번 픽셀 생성:**
   - 빈 이미지 전체를 네트워크에 통과시킨다.
   - 1번 위치의 확률 분포를 계산하고 샘플링하여 채운다.
3. **2번 픽셀 생성:**
   - **1번 픽셀이 채워진 이미지 전체**를 다시 네트워크에 통과시킨다.
   - 2번 위치의 확률 분포를 계산하고 샘플링하여 채운다.
4. **...반복...**
5. **12번째 픽셀 생성:**
   - **1번부터 11번까지 픽셀이 채워진 이미지 전체**를 네트워크에 통과시킨다.
   - Masking 덕분에 네트워크는 1~11번 픽셀의 정보(Context)만을 참고하여 12번 위치의 값을 예측한다.
   - 나온 확률 분포에서 값을 하나 뽑아(Sampling) 12번 픽셀을 채운다.



즉, **지금까지 만들어진 모든 픽셀들이 현재 내가 만들려는 위치의 픽셀에 영향을 끼친다**는 말이다.

LSTM은 이전 단계의 '기억(Hidden State)'만 넘겨받아 처리하는 방식이라면, PixelCNN은 **부분적으로 완성된 이미지 전체를 매번 입력으로 다시 넣는 구조**다. 그렇기 때문에 LSTM과는 구조적 결이 완전히 다르며, 이 "전체를 다시 넣는" 방식 때문에 병렬화가 가능한 학습(Training)과 달리 생성(Inference) 속도는 필연적으로 느려질 수밖에 없다.