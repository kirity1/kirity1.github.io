---
key:
title: 'pixelcnn 전처리'
excerpt: 'pixelcnn'
tags: [컴퓨터비전]
---

PixelCNN 구현에 필요한 PyTorch 및 시각화 라이브러리를 임포트한다.
특히 Colab 환경에서 학습 시간이 길어질 경우 세션이 끊겨 결과가 날아가는 것을 방지하기 위해, **Google Drive를 마운트하여 체크포인트와 결과 이미지를 저장**하도록 설정했다.

```py
# 첫 번째 셀: 라이브러리 임포트
import os
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import datasets, transforms
from torchvision.utils import save_image, make_grid

from google.colab import drive
drive.mount('/content/drive')

# 저장 경로 설정
import os
DRIVE_PATH = '/content/drive/MyDrive/pixelcnn_results'
os.makedirs(DRIVE_PATH, exist_ok=True)
print(f"결과가 저장될 경로: {DRIVE_PATH}")
```

```py
# 두 번째 셀: 하이퍼파라미터 설정 
# PixelCNN 모델의 하이퍼파라미터
PARAMS = {
    # 데이터셋 설정
    'dataset_name': 'cifar10',  # 'mnist' 또는 'cifar10'
    'img_size': 32,
    'batch_size': 128,
    
    # 모델 아키텍처 설정
    'hidden_channels': 256,     # 128에서 256으로 증가
    'n_residual': 15,           # 5에서 15로 증가
    'kernel_size': 7,           # 첫 번째 레이어의 커널 크기
    
    # 학습 설정
    'epochs': 30,               # 15에서 30으로 증가
    'lr': 3e-4,
    'weight_decay': 1e-5,       # L2 정규화 추가
    'lr_scheduler_factor': 0.5,
    'lr_scheduler_patience': 5,
    
    # 생성 설정
    'temperature': 0.6,         
    'n_per_class': 2,
    
    # 저장 설정
    'save_dir': DRIVE_PATH,     # 구글 드라이브 경로로 변경
    'model_name': 'pixelcnn_improved'
}

# 설정 저장 함수
def save_config(config, filepath):
    """설정 저장"""
    import json
    with open(filepath, 'w') as f:
        json.dump(config, f, indent=4)

# 설정 파일 저장
save_config(PARAMS, f'{PARAMS["save_dir"]}/config.json')
```

```py
def save_config(config, filepath):
    """설정 저장"""
    import json
    with open(filepath, 'w') as f:
        json.dump(config, f, indent=4)
```

`PARAMS` 딕셔너리는 모델 학습에 필요한 모든 변수를 모아둔 것이다.

`save_config` 함수는 `PARAMS`를 받아서 지정된 경로(`save_dir`)에 `config.json` 형태로 저장한다. 이렇게 하면 나중에 설정 파일을 열어보고 "아, 이때 이런 세팅으로 돌렸구나" 하고 바로 알 수 있다.

**n_residual (15):** 레지듀얼 블록(Residual Block)의 개수다. 레이어를 깊게 쌓으면 학습이 잘 안 되는 문제를 해결하기 위해, 중간중간 건너뛰는(Skip Connection) 구조를 15번 반복해서 깊게 학습하겠다는 뜻이다.

**temperature (0.6):** 생성 모델에서 온도가 높으면(1.0 근접) 이미지가 다양해지지만 노이즈가 심해진다. 초기 실험 결과 0.8은 너무 깨지는 경향이 있어 0.6으로 낮추어(Scaling Down) 더 선명한 이미지를 얻고자 했다.





```py
# 세 번째 셀: 데이터 전처리 및 로딩 함수 (약간 수정)
def load_dataset(dataset_name='cifar10', batch_size=128, img_size=32):
    if dataset_name.lower() == 'cifar10':
        # CIFAR-10 데이터셋 설정
        transform = transforms.Compose([
            transforms.Resize((img_size, img_size)),
            transforms.ToTensor()
        ])
        
        train_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform)
        test_dataset = datasets.CIFAR10('./data', train=False, download=True, transform=transform)
        n_classes = 10
        in_channels = 3
        
    elif dataset_name.lower() == 'mnist':
        # MNIST 데이터셋 설정
        transform = transforms.Compose([
            transforms.Resize((img_size, img_size)),
            transforms.ToTensor()
        ])
        
        train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
        test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)
        n_classes = 10
        in_channels = 1
        
    else:
        raise ValueError(f"지원하지 않는 데이터셋: {dataset_name}")
        
    # 데이터로더 생성
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)
    
    return train_loader, test_loader, n_classes, in_channels
```

torchvision의 데이터셋에는 minst, cifar10 등 다양하게 있으니까 저런식으로 구별해놨다, 

```py
train_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform)
```

download=True 매개변수와 함께 사용되면, PyTorch는 지정된 경로(여기서는 './data')에 CIFAR10 데이터셋을 다운로드하고 저장

**1. shuffle: 데이터 다양성을 통한 학습 안정화**

매 에포크마다 데이터 순서를 무작위로 섞을지 결정하는 옵션이다. 단순해 보이지만 영향이 크다.

- **왜 섞어야 할까?** 안 섞으면 모델이 데이터의 '순서' 자체를 외워버리는(Order Bias) 문제가 생기거나, 비슷한 샘플만 연속으로 학습하다가 특정 유형에만 과적합(Local Optimization)될 수 있다.
- 그래서 **훈련(Train) 때는 `True`**로 해서 매번 섞어주고, **테스트(Test) 때는 `False`**로 해서 일관된 평가를 하는 게 정석이다.

**2. num_workers: 병렬 처리로 데이터 로딩 가속화**

데이터를 로드할 때 몇 개의 병렬 프로세스를 쓸지 정하는 거다.

- 너무 적으면 데이터 로딩이 느려서 GPU가 놀게 되고(병목 현상), 너무 많으면 CPU 리소스를 너무 잡아먹어서 오히려 느려진다.
- 보통 **CPU 코어 수의 절반 정도(여기선 4개)**로 설정하면 적절하다. 대규모 데이터셋일수록 이 옵션이 중요해진다.

**3. pin_memory: GPU 전송 최적화**

CPU 메모리의 페이지를 고정(Pinning)해서 GPU로 데이터를 더 빨리 쏘게 해주는 옵션이다.

- **동작 원리:** 원래 CPU 메모리는 주소가 바뀔 수 있는데(가상 메모리), `pin_memory=True`를 하면 **"이 데이터는 여기 딱 고정해!"**라고 박아두는 거다(Page-locked).
- 이렇게 고정된 메모리는 CPU에서 GPU로 보낼 때 훨씬 빠르다. 코랩이나 서버에서 GPU 학습할 땐 무조건 켜는 게 이득이다.