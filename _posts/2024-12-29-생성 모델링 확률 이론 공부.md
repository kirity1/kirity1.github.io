---
key:
title: '생성 모델링 확률 이론 공부'
excerpt: '확률 이론 기본적인 공부'
tags: [확률이론]
---

## 확률 밀도 함수

확률 밀도 함수란 어떠한 X집합(X = x1,x2,x3...)이 있을 떄, 0과 1 사이의 숫자로 매핑하는 함수 P(x), 표본 공간에 있는 모든 포안트에 대해 밀도 함수를 적분 했을 떄 1이 되어야 한다.

이 떄 관측 데이터 셋을 생성한 실제 밀도 함수 $P_{data}(x)$ 는 하나지만, 이 밀도 함수를 추정하는데 사용할 수 있는 밀도 함수 $P_{model}(x)$는 무수히 많다, 즉 실제 밀도 함수를 구하는게 모델링 입장에선 베스트겠지만, 불가능 하기 떄문에 저 함수를 추정하는 밀도 함수 $P_{model}(x)$ 중에서 가장 원본과 가까운 함수를 구하고자, 관측 데이터 셋에 가장 가깝게 찍어 내는 모델 함수를 구하고자 하는거다.

```python
import numpy as np
import matplotlib.pyplot as plt

# Data generation
np.random.seed(42)

# Real data distribution (pdata(x))
real_data = np.random.normal(loc=0, scale=1, size=1000)

# Multiple model distributions (pmodel(x))
model1 = np.random.normal(loc=0.1, scale=1.1, size=1000)
model2 = np.random.normal(loc=-0.1, scale=0.9, size=1000)
model3 = np.random.normal(loc=0, scale=1.2, size=1000)

# Visualization
plt.figure(figsize=(15, 10))

# 1. Real data distribution
plt.subplot(2, 2, 1)
plt.hist(real_data, bins=50, density=True, alpha=0.7, color='blue')
plt.title('Real Data Distribution (pdata(x))\nmean=0, std=1')
plt.grid(True)

# 2. Model 1
plt.subplot(2, 2, 2)
plt.hist(model1, bins=50, density=True, alpha=0.7, color='red')
plt.title('Model 1 Distribution (pmodel1(x))\nmean=0.1, std=1.1')
plt.grid(True)

# 3. Model 2
plt.subplot(2, 2, 3)
plt.hist(model2, bins=50, density=True, alpha=0.7, color='green')
plt.title('Model 2 Distribution (pmodel2(x))\nmean=-0.1, std=0.9')
plt.grid(True)

# 4. Model 3
plt.subplot(2, 2, 4)
plt.hist(model3, bins=50, density=True, alpha=0.7, color='purple')
plt.title('Model 3 Distribution (pmodel3(x))\nmean=0, std=1.2')
plt.grid(True)

plt.tight_layout()
plt.show()

# Compare all distributions in one graph
plt.figure(figsize=(12, 6))
plt.hist(real_data, bins=50, density=True, alpha=0.5, color='blue', label='Real Data')
plt.hist(model1, bins=50, density=True, alpha=0.5, color='red', label='Model 1')
plt.hist(model2, bins=50, density=True, alpha=0.5, color='green', label='Model 2')
plt.hist(model3, bins=50, density=True, alpha=0.5, color='purple', label='Model 3')
plt.title('Comparison of All Distributions')
plt.legend()
plt.grid(True)
plt.show()
```

## 모수 모델링

안정적인 $P_{model}(x)$를 찾는 데 사용하는 기법, **모수 모델**이란 유한한 개수의 파라미터(무엇이 되었던 간에)를 사용해 기술 할 수 있는 밀도 함수, 즉 파라미터들을 가지고 어떤 확률 분포를 구하고자 할 떄를 말한다,

```py
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# Set random seed for reproducibility
np.random.seed(42)

class ParametricModeling:
    def __init__(self, data):
        self.data = data
        # Estimate parameters using MLE (Maximum Likelihood Estimation)
        self.mean = np.mean(data)
        self.std = np.std(data)
        
    def fit_normal(self):
        """Fit normal distribution to data"""
        return stats.norm(self.mean, self.std)
    
    def generate_samples(self, n_samples):
        """Generate new samples from fitted distribution"""
        return np.random.normal(self.mean, self.std, n_samples)
    
    def plot_comparison(self):
        """Plot original data vs fitted parametric model"""
        plt.figure(figsize=(12, 6))
        
        # Plot original data histogram
        plt.hist(self.data, bins=50, density=True, alpha=0.7, 
                color='blue', label='Original Data')
        
        # Plot fitted parametric model
        x = np.linspace(min(self.data), max(self.data), 100)
        fitted_dist = self.fit_normal()
        plt.plot(x, fitted_dist.pdf(x), 'r-', lw=2, 
                label=f'Fitted Normal (μ={self.mean:.2f}, σ={self.std:.2f})')
        
        plt.title('Parametric Modeling: Data vs Fitted Distribution')
        plt.xlabel('Value')
        plt.ylabel('Density')
        plt.legend()
        plt.grid(True)
        plt.show()
        
    def goodness_of_fit(self):
        """Perform Kolmogorov-Smirnov test for normality"""
        ks_statistic, p_value = stats.kstest(self.data, 'norm', 
                                           args=(self.mean, self.std))
        return {
            'KS Statistic': ks_statistic,
            'p-value': p_value,
            'Is Normal': p_value > 0.05
        }

# Generate example data (mixture of two normal distributions)
n_samples = 1000
data1 = np.random.normal(0, 1, n_samples // 2)
data2 = np.random.normal(3, 1.5, n_samples // 2)
mixed_data = np.concatenate([data1, data2])

# Create and fit parametric model
model = ParametricModeling(mixed_data)

# Plot the comparison
model.plot_comparison()

# Generate new samples
new_samples = model.generate_samples(1000)

# Compare original and generated distributions
plt.figure(figsize=(12, 6))
plt.hist(mixed_data, bins=50, density=True, alpha=0.7, 
         color='blue', label='Original Data')
plt.hist(new_samples, bins=50, density=True, alpha=0.7, 
         color='red', label='Generated Samples')
plt.title('Comparison: Original vs Generated Data')
plt.xlabel('Value')
plt.ylabel('Density')
plt.legend()
plt.grid(True)
plt.show()

# Print goodness of fit results
fit_results = model.goodness_of_fit()
print("\nGoodness of Fit Test Results:")
for key, value in fit_results.items():
    print(f"{key}: {value}")
```

물론 그런다고 정확하게 예측되는게 아니기 떄문에, 저렇게 데이터가 예측이랑 빗나가는 경우도 있다. 그래서 비모수적으로 하는 방법도 있는 듯 하다.

## 가능도

파라미터 집합 $\theta$ 의 가능도는 $L($\theta$ | x)$ 는 관측된 포이트 x가 주어졌을 떄 $\theta$의 타당성을 측정하는 함수이다.

