---
key:
title: '확률분포예측,최대가능도 추정'
excerpt: 'deeplearning'
tags: [deeplearning]
---

## 예측, 점을 넘어 분포로: 모델이 불확실성을 이야기하는 방법
**(회귀 문제에서 Pr(y|x)와 최대 가능도 손실 함수의 이해)**

기존의 많은 머신러닝 회귀 모델은 입력 $x$가 주어졌을 때, 특정 출력값 $y$ 하나만을 예측하는 방식으로 작동한다. 예를 들어, "내일의 예상 기온은 25도"와 같이 명확한 하나의 숫자를 제시한다. 하지만 현실 세계의 많은 문제는 본질적으로 불확실성을 내포한다. "내일 기온이 정확히 25도일까, 아니면 24도나 26도일 가능성은 없을까?" 이런 질문에 답하기 위해, 모델이 단순히 점(point) 예측을 넘어 출력값에 대한 전체 **확률 분포(probability distribution)**를 예측하는 접근 방식이 중요해지고 있다.

### 1. 점 예측의 한계와 분포 예측의 등장

전통적인 회귀 모델은 입력 $x$에 대해 최적의 단일 예측값 $\hat{y}$를 찾는 것을 목표로 한다. 예를 들어, 최소 제곱 오차(Mean Squared Error, MSE)를 손실 함수로 사용하는 선형 회귀 모델은 평균적인 예측을 제공하려 하지만, 그 예측이 얼마나 확실한지에 대한 정보는 주지 않는다.

이에 반해, **분포 예측**은 입력 $x$가 주어졌을 때 가능한 모든 출력 $y$ 값들에 대한 확률을 나타내는 함수, 즉 **조건부 확률 분포 $Pr(y|x)$**를 모델링한다.
*   **$Pr(y|x)$란?**: "입력 $x$의 조건 하에서, 출력이 $y$일 확률"을 의미한다.
*   **시각화**: 만약 $y$가 연속적인 실수 값이라면, $Pr(y|x)$는 특정 $x$에 대해 종 모양의 곡선(예: 정규분포)으로 나타날 수 있다. 이 곡선의 넓이는 1이며, 특정 구간의 넓이는 $y$가 해당 구간에 속할 확률을 나타낸다. 곡선의 봉우리가 높은 곳은 $y$가 발생할 확률이 높은 지점이며, 넓게 퍼진 곡선은 예측의 불확실성이 크다는 것을 의미한다.

이러한 분포 예측은 "내일 기온은 평균 25도이고, 표준편차는 1.5도인 정규분포를 따를 것으로 예상된다"와 같이 훨씬 풍부한 정보를 제공할 수 있다. 이를 통해 우리는 예측값 주변의 신뢰 구간을 설정하거나, 특정 값 이상/이하일 확률 등을 계산할 수 있게 된다.

### 2. 모델은 어떻게 분포를 학습할까? - 손실 함수의 역할

모델이 $Pr(y|x)$라는 확률 분포를 예측하도록 학습시키기 위해서는 손실 함수의 역할이 중요하다. 여기서 핵심적인 아이디어는 **최대 가능도 추정 (Maximum Likelihood Estimation, MLE)**이다. MLE의 기본 원리는 "우리가 가지고 있는 학습 데이터 $\{x_i, y_i\}$가 현재 모델 하에서 나타날 가능성(가능도, likelihood)이 가장 높아지도록 모델의 파라미터(가중치, 편향 등)를 조정하자"는 것이다.

즉, 손실 함수는 각 학습 샘플 $(x_i, y_i)$에 대해, 모델이 예측한 분포 $Pr(y|x_i)$에서 실제 정답 $y_i$가 관찰될 확률을 최대화하도록 설계된다.

수학적으로는 보통 **음의 로그 가능도 (Negative Log-Likelihood, NLL)**를 최소화하는 형태로 손실 함수를 정의한다. 로그를 취하는 이유는 곱셈 연산을 덧셈 연산으로 바꿔 계산을 용이하게 하고, 음수를 취하는 이유는 최적화 문제에서 일반적으로 최소화 문제를 다루기 때문이다.
만약 모델 파라미터를 $\theta$라고 할 때, NLL 손실 함수는 다음과 같이 표현될 수 있다:
```math
\text{Loss}(\theta) = - \sum_{i=1}^{N} \log Pr(y_i | x_i; \theta)
```
여기서 $N$은 전체 학습 데이터의 수이다.

*   **작동 방식**:
    *   만약 특정 입력 $x_i$에 대해 모델이 예측한 분포 $Pr(y|x_i)$가 실제 정답 $y_i$ 근처에서 높은 확률 값을 가진다면 (즉, $Pr(y_i|x_i)$가 크다면), $\log Pr(y_i|x_i)$는 덜 음수가 되고, $-\log Pr(y_i|x_i)$는 작은 양수가 되어 손실이 작아진다.
    *   반대로, 모델이 실제 정답 $y_i$에 낮은 확률을 할당한다면, $\log Pr(y_i|x_i)$는 매우 큰 음수가 되고, $-\log Pr(y_i|x_i)$는 큰 양수가 되어 손실이 커진다.
    *   따라서 모델은 학습 과정에서 이 NLL 손실을 줄이기 위해 실제 정답에 높은 확률을 부여하는 방향으로 파라미터 $\theta$를 업데이트하게 된다.

### 3. 시각적으로 이해하기

(앞선 대화에서 언급된 그림 5.1(a)와 같은 상황을 상상해보자)
*   **X축**은 입력 변수 $x$, **Y축**은 출력 변수 $y$를 나타낸다.
*   **주황색 점들**은 우리가 가진 실제 학습 데이터 $(x_i, y_i)$ 쌍들을 나타낸다.
*   모델이 학습된 후, 특정 입력 $x_{test}$ (예: $x=2.0$ 또는 $x=7.0$)에 대해 모델이 예측하는 **출력 분포 $Pr(y|x_{test})$는 청록색 곡선(예: 정규분포의 확률 밀도 함수)으로 시각화**될 수 있다.
*   **잘 학습된 모델이라면**, 각 학습 데이터의 주황색 점 $y_i$는 해당 $x_i$에 대한 청록색 예측 분포 곡선에서 확률이 높은, 즉 곡선이 봉긋 솟아있는 부분에 위치하게 될 것이다. 손실 함수는 바로 이러한 상태를 목표로 모델을 이끌어간다.

### 4. 개념적 구현 단계

실제로 신경망 모델이 확률 분포를 예측하도록 하려면 다음과 같은 단계를 고려할 수 있다:

1.  **분포 선택**: 예측하려는 출력 $y$의 특성에 맞는 확률 분포를 선택한다.
    *   $y$가 일반적인 실수 값이라면 **정규분포(Gaussian distribution)**를 가정할 수 있다. 이 경우 모델은 각 입력 $x$에 대해 정규분포의 파라미터인 평균 $\mu(x)$와 분산 $\sigma^2(x)$ (또는 표준편차 $\sigma(x)$)를 예측해야 한다.
    *   $y$가 개수(count) 데이터라면 포아송 분포, 이산적인 클래스라면 다항분포(또는 소프트맥스 출력을 통한 카테고리컬 분포) 등을 사용할 수 있다.
2.  **모델 아키텍처**: 신경망의 마지막 레이어가 선택된 분포의 파라미터들을 출력하도록 설계한다.
    *   예를 들어 정규분포를 가정한다면, 네트워크는 두 개의 출력 노드를 가질 수 있다. 하나는 $\mu(x)$를 예측하고, 다른 하나는 $\log(\sigma^2(x))$ 또는 $\sigma(x)$를 예측한다. (분산은 항상 양수여야 하므로, 직접 분산을 예측하기보다는 로그-분산을 예측한 후 지수 함수를 취하거나, ReLU와 같은 활성화 함수를 통해 양수성을 보장하는 방법을 사용한다.)
3.  **손실 함수 구현**: 선택된 분포의 확률 밀도 함수(PDF)나 확률 질량 함수(PMF)를 사용하여 NLL을 계산한다.
    *   정규분포의 경우, $Pr(y|x; \mu(x), \sigma^2(x))$는 정규분포의 PDF가 된다. 이 PDF에 실제 $y_i$와 모델이 예측한 $\mu(x_i)$, $\sigma^2(x_i)$를 대입하여 가능도를 계산하고, 이를 통해 NLL 손실을 구성한다.

### 5. 분포 예측의 강력한 이점

출력에 대한 분포를 예측하는 방식은 다음과 같은 중요한 이점을 제공한다:

*   **불확실성 정량화**: 모델이 예측값과 함께 그 예측이 얼마나 확실한지에 대한 정보를 제공한다. 예를 들어, 예측된 분포의 분산이 크다면 모델이 해당 예측에 대해 불확실하다는 것을 의미한다. 이는 특히 안전이 중요한 분야(의료, 자율주행 등)에서 매우 중요하다.
*   **신뢰 구간 추정**: 예측된 분포로부터 신뢰 구간(confidence interval) 또는 예측 구간(prediction interval)을 쉽게 계산할 수 있다.
*   **더 나은 의사결정 지원**: 단순히 하나의 예측값만 보는 것보다, 가능한 결과의 범위를 이해하는 것이 더 합리적인 의사결정을 내리는 데 도움이 된다.
*   **이상치 탐지**: 학습 데이터에 없던 패턴의 입력이 들어왔을 때, 모델이 매우 넓은(불확실성이 큰) 분포를 출력하거나, 낮은 가능도를 할당함으로써 이상치를 탐지하는 데 활용될 수 있다.

결론적으로, 모델이 출력에 대한 확률 분포를 예측하도록 학습하는 것은 머신러닝 모델이 현실 세계의 불확실성을 더 잘 다루고, 더 풍부하며 신뢰할 수 있는 정보를 제공하도록 하는 강력한 패러다임이다. 이는 단순한 점 예측을 넘어, 모델의 예측에 대한 깊이 있는 이해를 가능하게 한다.

## 모델 학습의 비밀: 데이터는 어떻게 서로를 도울까?

(i.i.d. 가정과 배치 학습 속 확률 분포 예측)

우리가 머신러닝 모델, 특히 결과의 불확실성까지 예측하려는 모델을 학습시킬 때, 수많은 데이터 포인트를 활용한다. 예를 들어, 집값 예측 모델을 6만 채의 주택 데이터로 학습시킨다고 생각해보자. 이때 모델은 단순히 "이 집의 가격은 3억"이라고 예측하는 것을 넘어, "이 집의 가격은 평균 3억, 표준편차 0.2억인 정규분포를 따를 가능성이 높다"와 같이 확률 분포를 예측하려 할 수 있다.

이 과정에서 모델은 방대한 데이터를 어떻게 효율적으로 다루며, 각 데이터는 학습에 어떤 영향을 미칠까? 여기서 핵심은 바로 "독립적이고 동일하게 분포되어 있다 (independent and identically distributed, i.i.d.)"는 통계적 가정과, 실제 학습이 이루어지는 배치(batch) 단위의 처리 방식이다.

### 1. 모델의 예측: 점이 아닌 분포, 그리고 그 분포의 파라미터

먼저, 모델이 어떻게 각 데이터에 대해 확률 분포를 예측하는지 다시 한번 짚어보자.

- 개별 예측: 모델은 각각의 입력 데이터 $x_i$에 대해, 그에 해당하는 출력 $y_i$의 조건부 확률 분포 $Pr(y_i|x_i)$를 직접적으로 계산하는 것이 아니라, 그 분포를 특정짓는 파라미터 $\theta_i$를 예측한다.

- 예시 (정규분포): 만약 우리가 출력 $y_i$가 정규분포를 따른다고 가정했다면, 모델은 신경망 $f[x_i, \phi]$를 통해 각 입력 $x_i$에 대한 해당 정규분포의 평균 $\mu_i$와 분산 $\sigma_i^2$를 계산한다. 즉, 모델의 출력은 $\theta_i = (\mu_i, \sigma_i^2)$가 된다.

- 중요한 것은, 서로 다른 입력 $x_i$와 $x_j$에 대해서는 일반적으로 서로 다른 파라미터 $(\mu_i, \sigma_i^2)$와 $(\mu_j, \sigma_j^2)$가 예측된다는 점이다. 이는 각 데이터 포인트마다 고유한 특성을 반영한 맞춤형 확률 분포가 생성됨을 의미한다.

### 2. i.i.d. 가정의 힘

모델의 궁극적인 학습 목표는 주어진 모든 학습 데이터 $\{ (x_i, y_i) \}$가 현재 모델 하에서 가장 잘 설명되도록, 즉 나타날 가능성(가능도, likelihood)이 최대가 되도록 모델의 내부 파라미터 $\phi$를 찾는 것이다. 전체 데이터셋에 대한 이 결합 가능성을 효율적으로 다루기 위해 두 가지 중요한 통계적 가정이 필요하다.

- 동일하게 분포되어 있다 (Identically Distributed):

모든 데이터 포인트 $(x_i, y_i)$에 대해, 입력 $x_i$가 주어졌을 때 출력 $y_i$가 따르는 확률 분포의 수학적 형태(form)가 동일하다고 가정한다.

예를 들어, 첫 번째 주택 데이터의 가격이 (모델에 의해 예측된 특정 평균과 분산을 가진) 정규분포를 따른다면, 6만 번째 주택 데이터의 가격도 (그것만의 평균과 분산을 가진) 정규분포의 형태를 따른다고 보는 것이다. 이는 모든 데이터에 일관된 가능도 계산 방식을 적용할 수 있게 한다.

- 독립적이다 (Independent):

하나의 데이터 포인트 $(x_i, y_i)$의 관찰 결과(또는 그것이 특정 분포를 따를 확률)는 다른 데이터 포인트 $(x_j, y_j)$의 관찰 결과나 확률에 영향을 주지 않는다고 가정한다. 각 데이터 샘플은 마치 서로에게 아무런 정보도 주지 않고 독립적으로 뽑힌 것처럼 취급된다.

이 독립성 덕분에, 전체 학습 데이터셋 $(y_1, ..., y_I)$이 주어진 입력 $(x_1, ..., x_I)$ 하에서 나타날 결합 확률(총 가능도)은 각 데이터 포인트의 개별 조건부 확률들의 곱으로 간단하게 표현될 수 있다:

math

Apply to math.ipynb

  Pr(y_1, y_2, ..., y_I | x_1, x_2, ..., x_I; \phi) = \prod_{i=1}^{I} Pr(y_i|x_i; \phi)

여기서 $Pr(y_i|x_i; \phi)$는 모델 $f[x_i, \phi]$가 예측한 파라미터 $\theta_i$로 정의된 분포 하에서 $y_i$가 관찰될 확률이다.

이 두 가지 가정을 합쳐 i.i.d. 가정이라 부르며, 이는 수많은 머신러닝 알고리즘과 통계적 추론의 이론적 기반을 제공한다.

### 3. 실제 학습의 작동 방식: 배치 단위 처리와 가능도 계산

6만 개의 데이터를 한 번에 처리하여 위 곱셈을 계산하는 것은 현실적으로 어렵다. 그래서 딥러닝에서는 데이터를 작은 묶음, 즉 배치(batch)로 나누어 순차적으로 학습을 진행한다.

- 예시 시나리오:

- 전체 학습 데이터: 60,000개

- 배치 크기: 300개

- 이 경우, 총 $60000 / 300 = 200$개의 배치가 한 에포크(epoch, 전체 데이터셋을 한 번 학습하는 주기)를 구성한다.

- 하나의 배치(300개 샘플) 내에서의 처리 과정:

1. 모델은 현재 배치의 300개 입력 데이터 $x_1, x_2, ..., x_{300}$을 받는다.

1. 각 입력 $x_i$에 대해, 모델 $f[x_i, \phi]$는 해당 $x_i$에 대한 분포의 파라미터 $\theta_i = (\mu_i, \sigma_i^2)$ (정규분포 가정 시)를 계산한다. 이 과정에서 300개의 서로 다른 파라미터 세트가 생성되어, 300개의 (형태는 같지만 내용이 다른) 정규분포가 정의된다.

1. i.i.d. 가정 하에, 이 300개 샘플 각각에 대한 실제 출력 $y_i$가 해당 예측 분포 $Pr(y_i|\theta_i)$ 하에서 나타날 확률을 계산한다.

1. 이 300개 확률값들을 모두 곱하여 (또는 더 안정적인 계산을 위해 각 확률에 로그를 취한 후 모두 더하여 로그 가능도를 계산) 해당 배치에 대한 전체 가능도(또는 로그 가능도)를 얻는다.

1. 이 배치 가능도를 최대화하는 방향으로 (또는 음의 로그 가능도를 최소화하는 방향으로) 모델의 내부 파라미터 $\phi$를 약간 업데이트한다 (경사 하강법 사용).

이 과정이 200개의 모든 배치에 대해 순차적으로 반복되면 1 에포크가 완료되며, 모델은 이러한 에포크를 여러 번 반복하며 점차 데이터의 복잡한 패턴과 불확실성을 학습하게 된다.

### 4. 가정의 의미와 한계

i.i.d. 가정은 수학적 모델링과 계산을 간편하게 만들어주지만, 현실 데이터가 항상 이 가정을 완벽하게 만족하지는 않는다. 예를 들어 시계열 데이터의 경우, 현재의 데이터 포인트가 과거의 데이터 포인트에 의존하는 경우가 많아 독립성 가정이 깨질 수 있다. 그럼에도 불구하고, i.i.d. 가정은 많은 경우에 유용한 근사치를 제공하며, 복잡한 현상을 이해하고 모델링하는 첫걸음이 된다.



그리고 Log를 사용해서 가능도를 나타내는데

### 왜 굳이 로그를 사용할까? 핵심은 '동등함'과 '실용성'

1. 동등성

로그 함수($\log(z)$)는 단조 증가(monotonically increasing) 함수다. 즉, 입력값 $z$가 커지면 $\log(z)$ 값도 항상 커진다.

이 성질 때문에 중요한 사실이 하나 따라온다:

- 원래 가능도 함수 $L(\phi)$를 최대로 만드는 모델 파라미터 $\hat{\phi}$의 위치는, 로그 가능도 함수 $\log L(\phi)$를 최대로 만드는 파라미터 $\hat{\phi}$의 위치와 정확히 동일하다.

따라서 로그를 취한다고 해서 우리가 찾고자 하는 최적의 모델 파라미터가 달라지지 않는다. 목표는 여전히 같다.

2. 실용성

그렇다면 왜 번거롭게 로그를 취하는 걸까? 몇 가지 강력한 실용적 이점이 있다:

- 곱셈을 덧셈으로: 로그의 기본 성질 $\log(ab) = \log a + \log b$ 덕분에, 가능도 함수에서의 수많은 확률값들의 곱셈이 로그 가능도에서는 덧셈으로 바뀐다. 이는 미분 계산 등을 훨씬 간편하게 만들어준다.

- 수치 안정성 (언더플로우 방지): 확률값은 0과 1 사이의 작은 수다. 이런 작은 수들을 많이 곱하면 결과는 엄청나게 작아져서 컴퓨터가 유한한 정밀도로 표현하기 어려운 수준(언더플로우)이 될 수 있다. 하지만 로그를 취하면 이 문제가 크게 완화된다. 값의 스케일이 덧셈에 적합하게 바뀌고, 극단적으로 작은 값으로 인한 계산 오류를 줄일 수 있다.

![image-20250507133910565](https://raw.githubusercontent.com/kirity1/blogimg/master/uPic/image-20250507133910565.png)

### 결론

로그 가능도를 사용하는 것은 원래의 최대 가능도 원리를 포기하는 것이 아니다.

오히려, 최적의 모델을 찾는 목표는 그대로 유지하면서, 수학적 및 계산적 편의성과 안정성을 크게 높이는 현명한 방법이다.

이것이 바로 딥러닝을 포함한 많은 통계적 모델 학습에서 로그 가능도가 널리 활용되는 이유다.
