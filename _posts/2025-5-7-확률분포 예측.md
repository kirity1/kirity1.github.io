---
key:
title: '확률분포예측,최대가능도 추정'
excerpt: 'deeplearning'
tags: [인공지능]
---

## 예측을 분포로: 모델의 불확실성(훈련 단계)

기존의 많은 머신러닝 회귀 모델은 입력 $x$가 주어졌을 때, 특정 출력값 $y$ 하나만을 예측하는 방식으로 작동한다. 예를 들어, "내일의 예상 기온은 25도"와 같이 명확한 하나의 숫자를 제시한다. 하지만 현실 세계의 많은 문제는 본질적으로 불확실성을 내포한다. "내일 기온이 정확히 25도일까, 아니면 24도나 26도일 가능성은 없을까?" 이런 질문에 답하기 위해, 모델이 단순히 점(point) 예측을 넘어 출력값에 대한 전체 **확률 분포(probability distribution)**를 예측하는 접근 방식이 중요해지고 있다.

### 점 예측의 한계와 분포 예측의 등장

전통적인 회귀 모델은 입력 $x$에 대해 최적의 단일 예측값 $\hat{y}$를 찾는 것을 목표로 한다. 예를 들어, 최소 제곱 오차(Mean Squared Error, MSE)를 손실 함수로 사용하는 선형 회귀 모델은 평균적인 예측을 제공하려 하지만, 그 예측이 얼마나 확실한지에 대한 정보는 주지 않는다.

이에 반해, **분포 예측**은 입력 $x$가 주어졌을 때 가능한 모든 출력 $y$ 값들에 대한 확률을 나타내는 함수, 즉 **조건부 확률 분포 $Pr(y\|x)$**를 모델링한다.

*   $Pr(y\|x)$란?: "입력 $x$의 조건 하에서, 출력이 $y$일 확률"을 의미한다.
*   시각화: 만약 $y$가 연속적인 실수 값이라면, $Pr(y\|x)$는 특정 $x$에 대해 종 모양의 곡선(예: 정규분포)으로 나타날 수 있다. 이 곡선의 넓이는 1이며, 특정 구간의 넓이는 $y$가 해당 구간에 속할 확률을 나타낸다. 곡선의 봉우리가 높은 곳은 $y$가 발생할 확률이 높은 지점이며, 넓게 퍼진 곡선은 예측의 불확실성이 크다는 것을 의미한다.

이러한 분포 예측은 "내일 기온은 평균 25도이고, 표준편차는 1.5도인 정규분포를 따를 것으로 예상된다"와 같이 훨씬 풍부한 정보를 제공할 수 있다. 이를 통해 우리는 예측값 주변의 신뢰 구간을 설정하거나, 특정 값 이상/이하일 확률 등을 계산할 수 있게 된다.

### 모델은 어떻게 분포를 학습할까? 

모델이 $Pr(y\|x)$라는 확률 분포를 예측하도록 학습시키기 위해서는 손실 함수의 역할이 중요하다. 여기서 핵심적인 아이디어는 **최대 가능도 추정 (Maximum Likelihood Estimation, MLE)**이다. MLE의 기본 원리는 "우리가 가지고 있는 학습 데이터 $\{x_i, y_i\}$가 현재 모델 하에서 나타날 가능성(가능도, likelihood)이 가장 높아지도록 모델의 파라미터(가중치, 편향 등)를 조정하자"는 것이다.

즉, 손실 함수는 각 학습 샘플 $(x_i, y_i)$에 대해, 모델이 예측한 분포 $Pr(y\|x_i)$에서 실제 정답 $y_i$가 관찰될 확률을 최대화하도록 설계된다.

수학적으로는 보통 **음의 로그 가능도 (Negative Log-Likelihood, NLL)**를 최소화하는 형태로 손실 함수를 정의한다. 로그를 취하는 이유는 곱셈 연산을 덧셈 연산으로 바꿔 계산을 용이하게 하고, 음수를 취하는 이유는 최적화 문제에서 일반적으로 최소화 문제를 다루기 때문이다.
만약 모델 파라미터를 $\theta$라고 할 때, NLL 손실 함수는 다음과 같이 표현될 수 있다:
$$
\text{Loss}(\theta) = - \sum_{i=1}^{N} \log Pr(y_i \| x_i; \theta)
$$
여기서 $N$은 전체 학습 데이터의 수이다.

*   작동 방식:
    *   만약 특정 입력 $x_i$에 대해 모델이 예측한 분포 $Pr(y\|x_i)$가 실제 정답 $y_i$ 근처에서 높은 확률 값을 가진다면 (즉, $Pr(y_i\|x_i)$가 크다면), $\log Pr(y_i\|x_i)$는 덜 음수가 되고, $-\log Pr(y_i\|x_i)$는 작은 양수가 되어 손실이 작아진다.
    *   반대로, 모델이 실제 정답 $y_i$에 낮은 확률을 할당한다면, $\log Pr(y_i\|x_i)$는 매우 큰 음수가 되고, $-\log Pr(y_i\|x_i)$는 큰 양수가 되어 손실이 커진다.
    *   따라서 모델은 학습 과정에서 이 NLL 손실을 줄이기 위해 실제 정답에 높은 확률을 부여하는 방향으로 파라미터 $\theta$를 업데이트하게 된다.

### 시각적으로 이해하기

![image-20250512113936132](https://raw.githubusercontent.com/kirity1/blogimg/master/uPic/image-20250512113936132.png)

*   X축은 입력 변수 $x$, Y축은 출력 변수 $y$를 나타낸다.
*   주황색 점들은 우리가 가진 실제 학습 데이터 $(x_i, y_i)$ 쌍들을 나타낸다.
*   모델이 학습된 후, 특정 입력 $x_{test}$ (예: $x=2.0$ 또는 $x=7.0$)에 대해 모델이 예측하는 출력 분포 $Pr(y\|x_{test})$는 청록색 곡선(예: 정규분포의 확률 밀도 함수)으로 시각화될 수 있다.
*   잘 학습된 모델이라면, 각 학습 데이터의 주황색 점 $y_i$는 해당 $x_i$에 대한 청록색 예측 분포 곡선에서 확률이 높은, 즉 곡선이 봉긋 솟아있는 부분에 위치하게 될 것이다. 손실 함수는 바로 이러한 상태를 목표로 모델을 이끌어간다.

### 개념적 구현 단계

실제로 신경망 모델이 확률 분포를 예측하도록 하려면 다음과 같은 단계를 고려할 수 있다:

1.  **분포 선택**: 예측하려는 출력 $y$의 특성에 맞는 확률 분포를 선택한다.
    *   $y$가 일반적인 실수 값이라면 **정규분포(Gaussian distribution)**를 가정할 수 있다. 이 경우 모델은 각 입력 $x$에 대해 정규분포의 파라미터인 평균 $\mu(x)$와 분산 $\sigma^2(x)$ (또는 표준편차 $\sigma(x)$)를 예측해야 한다.
    *   $y$가 개수(count) 데이터라면 포아송 분포, 이산적인 클래스라면 다항분포(또는 소프트맥스 출력을 통한 카테고리컬 분포) 등을 사용할 수 있다.
2.  **모델 아키텍처**: 신경망의 마지막 레이어가 선택된 분포의 파라미터들을 출력하도록 설계한다.
    *   예를 들어 정규분포를 가정한다면, 네트워크는 두 개의 출력 노드를 가질 수 있다. 하나는 $\mu(x)$를 예측하고, 다른 하나는 $\log(\sigma^2(x))$ 또는 $\sigma(x)$를 예측한다. (분산은 항상 양수여야 하므로, 직접 분산을 예측하기보다는 로그-분산을 예측한 후 지수 함수를 취하거나, ReLU와 같은 활성화 함수를 통해 양수성을 보장하는 방법을 사용한다.)
3.  **손실 함수 구현**: 선택된 분포의 확률 밀도 함수(PDF)나 확률 질량 함수(PMF)를 사용하여 NLL을 계산한다.
    *   정규분포의 경우, $Pr(y\|x; \mu(x), \sigma^2(x))$는 정규분포의 PDF가 된다. 이 PDF에 실제 $y_i$와 모델이 예측한 $\mu(x_i)$, $\sigma^2(x_i)$를 대입하여 가능도를 계산하고, 이를 통해 NLL 손실을 구성한다.

![image-20250512114143697](https://raw.githubusercontent.com/kirity1/blogimg/master/uPic/image-20250512114143697.png)

### 분포 예측의 강력한 이점

출력에 대한 분포를 예측하는 방식은 다음과 같은 중요한 이점을 제공한다:

*   **불확실성 정량화**: 모델이 예측값과 함께 그 예측이 얼마나 확실한지에 대한 정보를 제공한다. 예를 들어, 예측된 분포의 분산이 크다면 모델이 해당 예측에 대해 불확실하다는 것을 의미한다. 이는 특히 안전이 중요한 분야(의료, 자율주행 등)에서 매우 중요하다.
*   **신뢰 구간 추정**: 예측된 분포로부터 신뢰 구간(confidence interval) 또는 예측 구간(prediction interval)을 쉽게 계산할 수 있다.
*   **더 나은 의사결정 지원**: 단순히 하나의 예측값만 보는 것보다, 가능한 결과의 범위를 이해하는 것이 더 합리적인 의사결정을 내리는 데 도움이 된다.
*   **이상치 탐지**: 학습 데이터에 없던 패턴의 입력이 들어왔을 때, 모델이 매우 넓은(불확실성이 큰) 분포를 출력하거나, 낮은 가능도를 할당함으로써 이상치를 탐지하는 데 활용될 수 있다.

결론적으로, 모델이 출력에 대한 확률 분포를 예측하도록 학습하는 것은 머신러닝 모델이 현실 세계의 불확실성을 더 잘 다루고, 더 풍부하며 신뢰할 수 있는 정보를 제공하도록 하는 강력한 패러다임이다. 이는 단순한 점 예측을 넘어, 모델의 예측에 대한 깊이 있는 이해를 가능하게 한다.

## 데이터는 어떻게 서로를 도울까?

(i.i.d. 가정과 배치 학습 속 확률 분포 예측)

우리가 머신러닝 모델, 특히 결과의 불확실성까지 예측하려는 모델을 학습시킬 때, 수많은 데이터 포인트를 활용한다. 예를 들어, 집값 예측 모델을 6만 채의 주택 데이터로 학습시킨다고 생각해보자. 이때 모델은 단순히 "이 집의 가격은 3억"이라고 예측하는 것을 넘어, "이 집의 가격은 평균 3억, 표준편차 0.2억인 정규분포를 따를 가능성이 높다"와 같이 확률 분포를 예측하려 할 수 있다.

이 과정에서 모델은 방대한 데이터를 어떻게 효율적으로 다루며, 각 데이터는 학습에 어떤 영향을 미칠까? 여기서 핵심은 바로 "독립적이고 동일하게 분포되어 있다 (independent and identically distributed, i.i.d.)"는 통계적 가정과, 실제 학습이 이루어지는 배치(batch) 단위의 처리 방식이다.

### 모델의 예측: 점이 아닌 분포, 그리고 그 분포의 파라미터

먼저, 모델이 어떻게 각 데이터에 대해 확률 분포를 예측하는지 다시 한번 짚어보자.

- 개별 예측: 모델은 각각의 입력 데이터 $x_i$에 대해, 그에 해당하는 출력 $y_i$의 조건부 확률 분포 $Pr(y_i\|x_i)$를 직접적으로 계산하는 것이 아니라, 그 분포를 특정짓는 파라미터 $\theta_i$를 예측한다.

- 예시 (정규분포): 만약 우리가 출력 $y_i$가 정규분포를 따른다고 가정했다면, 모델은 신경망 $f[x_i, \phi]$를 통해 각 입력 $x_i$에 대한 해당 정규분포의 평균 $\mu_i$와 분산 $\sigma_i^2$를 계산한다. 즉, 모델의 출력은 $\theta_i = (\mu_i, \sigma_i^2)$가 된다.

- 중요한 것은, 서로 다른 입력 $x_i$와 $x_j$에 대해서는 일반적으로 서로 다른 파라미터 $(\mu_i, \sigma_i^2)$와 $(\mu_j, \sigma_j^2)$가 예측된다는 점이다. 이는 각 데이터 포인트마다 고유한 특성을 반영한 맞춤형 확률 분포가 생성됨을 의미한다.

### i.i.d. 가정

모델의 궁극적인 학습 목표는 주어진 모든 학습 데이터 $\{ (x_i, y_i) \}$가 현재 모델 하에서 가장 잘 설명되도록, 즉 나타날 가능성(가능도, likelihood)이 최대가 되도록 모델의 내부 파라미터 $\phi$를 찾는 것이다. 전체 데이터셋에 대한 이 결합 가능성을 효율적으로 다루기 위해 두 가지 중요한 통계적 가정이 필요하다.

- 동일하게 분포되어 있다 (Identically Distributed):

모든 데이터 포인트 $(x_i, y_i)$에 대해, 입력 $x_i$가 주어졌을 때 출력 $y_i$가 따르는 확률 분포의 수학적 형태(form)가 동일하다고 가정한다.

예를 들어, 첫 번째 주택 데이터의 가격이 (모델에 의해 예측된 특정 평균과 분산을 가진) 정규분포를 따른다면, 6만 번째 주택 데이터의 가격도 (그것만의 평균과 분산을 가진) 정규분포의 형태를 따른다고 보는 것이다. 이는 모든 데이터에 일관된 가능도 계산 방식을 적용할 수 있게 한다.

- 독립적이다 (Independent):

하나의 데이터 포인트 $(x_i, y_i)$의 관찰 결과(또는 그것이 특정 분포를 따를 확률)는 다른 데이터 포인트 $(x_j, y_j)$의 관찰 결과나 확률에 영향을 주지 않는다고 가정한다. 각 데이터 샘플은 마치 서로에게 아무런 정보도 주지 않고 독립적으로 뽑힌 것처럼 취급된다.

이 독립성 덕분에, 전체 학습 데이터셋 $(y_1, ..., y_I)$이 주어진 입력 $(x_1, ..., x_I)$ 하에서 나타날 결합 확률(총 가능도)은 각 데이터 포인트의 개별 조건부 확률들의 곱으로 간단하게 표현될 수 있다:

$$
Pr(y_1, y_2, ..., y_I \| x_1, x_2, ..., x_I; \phi) = \prod_{i=1}^{I} Pr(y_i\|x_i; \phi)
$$
여기서 $Pr(y_i\|x_i; \phi)$는 모델 $f[x_i, \phi]$가 예측한 파라미터 $\theta_i$로 정의된 분포 하에서 $y_i$가 관찰될 확률이다.

이 두 가지 가정을 합쳐 i.i.d. 가정이라 부르며, 이는 수많은 머신러닝 알고리즘과 통계적 추론의 이론적 기반을 제공한다.

### 배치 단위 처리와 가능도 계산

6만 개의 데이터를 한 번에 처리하여 위 곱셈을 계산하는 것은 현실적으로 어렵다. 그래서 딥러닝에서는 데이터를 작은 묶음, 즉 배치(batch)로 나누어 순차적으로 학습을 진행한다.

- 예시 시나리오:

- 전체 학습 데이터: 60,000개

- 배치 크기: 300개

- 이 경우, 총 $60000 / 300 = 200$개의 배치가 한 에포크(epoch, 전체 데이터셋을 한 번 학습하는 주기)를 구성한다.

- 하나의 배치(300개 샘플) 내에서의 처리 과정:

1. 모델은 현재 배치의 300개 입력 데이터 $x_1, x_2, ..., x_{300}$을 받는다.

1. 각 입력 $x_i$에 대해, 모델 $f[x_i, \phi]$는 해당 $x_i$에 대한 분포의 파라미터 $\theta_i = (\mu_i, \sigma_i^2)$ (정규분포 가정 시)를 계산한다. 이 과정에서 300개의 서로 다른 파라미터 세트가 생성되어, 300개의 (형태는 같지만 내용이 다른) 정규분포가 정의된다.

1. i.i.d. 가정 하에, 이 300개 샘플 각각에 대한 실제 출력 $y_i$가 해당 예측 분포 $Pr(y_i\|\theta_i)$ 하에서 나타날 확률을 계산한다.

1. 이 300개 확률값들을 모두 곱하여 (또는 더 안정적인 계산을 위해 각 확률에 로그를 취한 후 모두 더하여 로그 가능도를 계산) 해당 배치에 대한 전체 가능도(또는 로그 가능도)를 얻는다.

1. 이 배치 가능도를 최대화하는 방향으로 (또는 음의 로그 가능도를 최소화하는 방향으로) 모델의 내부 파라미터 $\phi$를 약간 업데이트한다 (경사 하강법 사용).

이 과정이 200개의 모든 배치에 대해 순차적으로 반복되면 1 에포크가 완료되며, 모델은 이러한 에포크를 여러 번 반복하며 점차 데이터의 복잡한 패턴과 불확실성을 학습하게 된다.

### 가정의 의미와 한계

i.i.d. 가정은 수학적 모델링과 계산을 간편하게 만들어주지만, 현실 데이터가 항상 이 가정을 완벽하게 만족하지는 않는다. 예를 들어 시계열 데이터의 경우, 현재의 데이터 포인트가 과거의 데이터 포인트에 의존하는 경우가 많아 독립성 가정이 깨질 수 있다. 그럼에도 불구하고, i.i.d. 가정은 많은 경우에 유용한 근사치를 제공하며, 복잡한 현상을 이해하고 모델링하는 첫걸음이 된다.

그리고 Log를 사용해서 가능도를 나타내는데

### 왜 굳이 로그를 사용할까?

1.  동등성

로그 함수($\log(z)$)는 단조 증가(monotonically increasing) 함수다. 즉, 입력값 $z$가 커지면 $\log(z)$ 값도 항상 커진다.

이 성질 때문에 중요한 사실이 하나 따라온다:

- 원래 가능도 함수 $L(\phi)$를 최대로 만드는 모델 파라미터 $\hat{\phi}$의 위치는, 로그 가능도 함수 $\log L(\phi)$를 최대로 만드는 파라미터 $\hat{\phi}$의 위치와 정확히 동일하다.

따라서 로그를 취한다고 해서 우리가 찾고자 하는 최적의 모델 파라미터가 달라지지 않는다. 목표는 여전히 같다.

2.  실용성

그렇다면 왜 번거롭게 로그를 취하는 걸까? 몇 가지 강력한 실용적 이점이 있다:

- 곱셈을 덧셈으로: 로그의 기본 성질 $\log(ab) = \log a + \log b$ 덕분에, 가능도 함수에서의 수많은 확률값들의 곱셈이 로그 가능도에서는 덧셈으로 바뀐다. 이는 미분 계산 등을 훨씬 간편하게 만들어준다.

- 수치 안정성 (언더플로우 방지): 확률값은 0과 1 사이의 작은 수다. 이런 작은 수들을 많이 곱하면 결과는 엄청나게 작아져서 컴퓨터가 유한한 정밀도로 표현하기 어려운 수준(언더플로우)이 될 수 있다. 하지만 로그를 취하면 이 문제가 크게 완화된다. 값의 스케일이 덧셈에 적합하게 바뀌고, 극단적으로 작은 값으로 인한 계산 오류를 줄일 수 있다.

![image-20250507133910565](https://raw.githubusercontent.com/kirity1/blogimg/master/uPic/image-20250507133910565.png)

근데 이제 여긴 손실 함수를 표현할려는 거기땜에 -방향으로 최소화하는 방향으로 하는거기땜에 그냥 -를 곱해주면 손실함수로 표현 할 수 있다.

![image-20250507134054450](https://raw.githubusercontent.com/kirity1/blogimg/master/uPic/image-20250507134054450.png)

## 모델의 최종 예측: 분포에서 단일 값으로 (추론 단계의 이해)

지금까지 모델이 입력 $x$에 대해 출력 $y$의 단순한 값 대신, $y$에 대한 전체 확률 분포 $Pr(y\|x)$를 예측하도록 설계하고 학습시키는 과정을 살펴보았다.

이는 모델이 예측의 불확실성까지 표현할 수 있게 하는 강력한 방법이다.

하지만 모델 학습이 완료된 후, 새로운 입력에 대해 실제 예측을 수행하는 추론(Inference) 단계에서는 종종 분포 전체보다는 하나의 명확한 값, 즉 단일 값 예측(point estimate)이 필요한 경우가 많다.

예를 들어, "내일 비가 올 확률 분포"도 중요하지만, "그래서 내일 비가 온다고 예측하는가, 안 온다고 예측하는가?"라는 구체적인 답을 원할 수 있다.

### 1. 분포에서 단일 값으로: 최빈값(Mode) 활용

모델이 출력 $y$에 대한 확률 분포 $Pr(y\|f[x, \hat{\phi}])$를 제공할 때 (여기서 $\hat{\phi}$는 학습된 최적의 모델 파라미터), 가장 직관적인 단일 값 예측 $\hat{y}$는 이 분포에서 확률이 가장 높은 지점의 $y$ 값을 선택하는 것이다.

이는 통계적으로 분포의 최빈값(mode)을 찾는 것과 같다.

수학적으로는 다음과 같이 표현된다:
$$
\hat{y} = \text{argmax}_{y} \left[ Pr(y\|f[x, \hat{\phi}]) \right]
$$
위 식에서 $\text{argmax}*{y}$는 대괄호 안의 확률 $Pr(y\|f[x, \hat{\phi}])$을 최대로 만드는 $y$ 값을 찾는다는 의미다.*

즉, 모델이 "이 입력 $x$에 대해서는 $y$가 이 지점에서 나타날 가능성이 가장 높습니다"라고 말하는 그 지점을 우리의 최종 예측값 $\hat{y}$로 선택하는 것이다.

### 2. 분포 파라미터와 단일 예측값의 관계

그렇다면 이 최빈값 $\hat{y}$는 어떻게 찾을 수 있을까?

다행히도, 모델이 예측하는 것은 분포 자체가 아니라 그 분포를 정의하는 파라미터 $\theta = f[x, \hat{\phi}]$ (예: 평균 $\mu$, 분산 $\sigma^2$)이다.

그리고 많은 표준적인 확률 분포에서, 최빈값은 이러한 파라미터들로부터 직접적으로, 혹은 간단한 계산을 통해 얻어진다.

- 대표적 예시: 정규분포 (Normal Distribution)

만약 우리 모델이 $y$가 정규분포를 따른다고 가정하고, 특정 입력 $x$에 대해 평균 $\mu(x)$와 분산 $\sigma^2(x)$를 예측했다면, 정규분포의 확률 밀도 함수는 그 평균 $\mu(x)$에서 최댓값을 가진다.

따라서, 이 경우 우리의 단일 예측값 $\hat{y}$는 단순히 모델이 예측한 평균값, 즉 $\hat{y} = \mu(x)$가 된다. 네트워크가 $\mu(x)$를 출력하면, 그것이 바로 우리가 원하는 점 추정치가 되는 것이다.

- 다른 분포의 경우

다른 종류의 분포를 가정했더라도 (예: 이산적인 값을 위한 포아송 분포나 다항 분포), 해당 분포의 최빈값은 그 분포의 파라미터로부터 결정될 수 있는 경우가 많다.

### 3. 결론: 불확실성 속 명확한 답 찾기

결국, 모델이 출력에 대한 확률 분포를 예측하도록 하는 접근 방식은 예측의 불확실성을 정량화하는 데 매우 유용하다.

그리고 추론 단계에서는 이 예측된 분포로부터 가장 가능성이 높은 단일 값을 추출함으로써, 실용적인 의사결정에 필요한 명확한 예측값을 얻을 수 있다.

이 과정은 모델이 데이터의 복잡한 확률적 특성을 학습하면서도, 필요에 따라 결정론적인 답변을 제공할 수 있도록 하는 유연성을 부여한다.

**정리하자면 가능도란 해당 값이 나왔을 타당한 확률 이런 느낌으로 실제 값 yi에 가깝게 나온 가능도가 높을수록, 즉 모델이 예측한 확률분포에서 실제 값이 나올 확률이 가장 크다면, 다시 말해 가장 큰 조건부확률을 가진다면, 모델이 yi를 잘 설명한거니까  당연히 손실,오차가 적다고 생각하면 된다.**

## NLL 손실

모델이 예측한 확률 분포 $Pr(y\|x)$ 하에서 실제 정답 $y_i$가 나타날 가능성을 최대화하거나, 음의 로그 가능도(NLL)를 최소화하도록 모델을 학습시킨다는 것은 이미 논의되었다. 이 NLL 손실, 즉 $-\log Pr(y_i \| x_i; \theta)$는 단순한 수학적 변환을 넘어 정보 이론(Information Theory)과 깊은 연관성을 가지며, 모델이 "얼마나 놀랐는지"를 측정하는 지표로 해석될 수 있다.

### 정보량과 놀람의 정도

어떤 사건의 발생 사실을 알게 되었을 때, 그 사건이 얼마나 드물거나 예상치 못한 것이었는지에 따라 얻게 되는 정보의 양은 달라진다. 예를 들어, "해가 동쪽에서 떴다"는 정보는 거의 놀랍지 않으므로 정보량이 적다. 반면, "한여름에 갑자기 눈이 펑펑 내릴 것이다"라는 정보는 매우 놀라우며 정보량이 많다고 할 수 있다.

정보 이론에서는 특정 사건 $E$가 발생할 확률을 $P(E)$라고 할 때, 이 사건의 발생으로부터 얻는 정보량(또는 "놀람의 정도", "자기 정보량(self-information)")을 다음과 같이 정의한다:
$$
I(E) = -\log P(E)
$$
여기서 로그의 밑은 2 (비트 단위), 자연상수 $e$ (내트 단위), 또는 10 등이 사용될 수 있으나, 최적화 관점에서는 어떤 밑을 사용하든 상수 배 차이이므로 결과에 영향을 주지 않는다.

이 정의로부터 다음 특징들을 파악할 수 있다:

1.  확률이 낮은 사건일수록 정보량이 크다: $P(E)$가 0에 가까울수록 (매우 드문 사건), $-\log P(E)$ 값은 커진다. 즉, 더 놀랍고 더 많은 정보를 전달한다.

2.  확률이 높은 사건일수록 정보량이 작다: $P(E)$가 1에 가까울수록 (매우 흔한 사건), $-\log P(E)$ 값은 0에 가까워진다. 즉, 덜 놀랍고 정보량이 적다.

3.  확률이 1인 사건의 정보량은 0이다: 반드시 일어나는 사건은 새로운 정보를 제공하지 않는다.

### NLL 손실

이 개념을 NLL 손실 함수에 연결해보자. 각 학습 데이터 포인트 $(x_i, y_i)$에 대한 손실 기여분 $-\log Pr(y_i \| x_i; \theta)$는, 모델이 입력 $x_i$를 보고 예측한 분포 $Pr(y \| x_i; \theta)$ 하에서 실제 정답 $y_i$를 관찰했을 때 모델이 느끼는 "놀람의 정도" 또는 "정보량"에 해당한다.

- 모델이 $y_i$를 높은 확률로 예측했다면 ($Pr(y_i \| x_i; \theta)$가 크다면), 모델은 "별로 놀라지 않았고", 해당 데이터 포인트에 대한 손실은 작다.

- 모델이 $y_i$를 낮은 확률로 예측했다면 ($Pr(y_i \| x_i; \theta)$가 작다면), 모델은 "매우 놀랐고", 해당 데이터 포인트에 대한 손실은 크다.

따라서 전체 학습 데이터셋에 대한 NLL 손실 $\text{Loss}(\theta) = - \sum_{i=1}^{N} \log Pr(y_i \| x_i; \theta)$를 최소화하는 과정은, 모델이 모든 학습 데이터에 대해 느끼는 "총 놀람의 양" 또는 "총 정보량"을 최소화하려는 시도로 해석할 수 있다. 다시 말해, 모델이 학습 데이터를 가장 "당연하게" 또는 "놀랍지 않게" 받아들이도록 파라미터 $\theta$를 조정하는 것이다.

이러한 관점은 NLL 손실이 왜 합리적인 손실 함수인지에 대한 또 다른 직관을 제공한다. 모델이 현실을 잘 반영한다면, 실제 발생하는 사건들에 대해 크게 놀라지 않아야 하며, NLL은 바로 이러한 특성을 정량화하여 모델 학습의 목표로 삼는다.
