---
key:
title: 'ë³€ì´í˜• ì˜¤í† ì¸ì½”ë” ì½”ë“œ ë§Œë“¤ì–´ë³´ê¸°'
excerpt: 'ë³€ì´í˜• ì˜¤í† ì¸ì½”ë”'
tags: [VAE]
---

```py
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° Fashion MNIST ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import numpy as np

# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • (Keras vae_fashion.ipynbì™€ ë™ì¼)
IMAGE_SIZE = 32        # ì´ë¯¸ì§€ í¬ê¸°
BATCH_SIZE = 100
EPOCHS = 5
EMBEDDING_DIM = 2      # ì ì¬ ê³µê°„ ì°¨ì›
BETA = 50        # ì¬êµ¬ì„± ì†ì‹¤ì— ëŒ€í•œ ê°€ì¤‘ì¹˜

# ë°ì´í„° ì „ì²˜ë¦¬: ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • ë° Tensor ë³€í™˜
transform = transforms.Compose([
    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
    transforms.ToTensor(),  # [0,1] ë²”ìœ„ì˜ í…ì„œë¡œ ë³€í™˜
])

# Fashion MNIST ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° DataLoader êµ¬ì„±
train_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)
test_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)

train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

# ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ ì‚¬ìš©)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

dataiter = iter(train_dataloader)
image , labels = next(dataiter)

print(labels)

images, _ = next(iter(train_dataloader))
print("ì…ë ¥ ì´ë¯¸ì§€ shape:", images.shape)  # [batch_size, 1, 32, 32]

plt.figure(figsize=(20,4))
for idx in range(10):
    plt.subplot(1,10, idx + 1)
    img = image[idx].numpy()
    img = np.transpose(img, (1,2,0))
    plt.axis('off')
    plt.imshow(img, cmap='gray', interpolation='none')
    
plt.show
```

tensor([1, 2, 6, 0, 3, 8, 6, 6, 4, 2, 5, 7, 2, 0, 8, 1, 2, 7, 1, 4, 8, 5, 8, 7,        0, 4, 6, 9, 5, 9, 2, 2, 2, 8, 7, 2, 0, 8, 4, 7, 7, 8, 4, 4, 3, 3, 4, 5,        9, 3, 9, 8, 1, 4, 9, 5, 0, 9, 8, 9, 4, 8, 0, 9, 9, 4, 7, 0, 5, 8, 8, 9,        9, 0, 4, 8, 8, 3, 4, 9, 5, 3, 6, 4, 9, 7, 3, 5, 4, 0, 3, 6, 3, 9, 5, 5,        1, 9, 1, 9])

ì…ë ¥ ì´ë¯¸ì§€ shape: torch.Size([100, 1, 32, 32])

![image-20250209041429910](https://raw.githubusercontent.com/kirity1/blogimg/master/uPic/image-20250209041429910.png)

```py
# 2. VAE ëª¨ë¸ ì •ì˜ (ì¸ì½”ë”, ì¬íŒŒë¼ë¯¸í„°ë¼ì´ì œì´ì…˜, ë””ì½”ë” í¬í•¨)
class VAE(nn.Module):
    def __init__(self, image_size=32, latent_dim=2):
        super(VAE, self).__init__()
        self.image_size = image_size #ìƒì„±ì initìœ¼ë¡œ í´ë˜ìŠ¤ë¥¼ ë§Œë“¤ ë•Œ ê°ì²´ ìƒíƒœë¥¼ ì €ì¥í•˜ì—¬ í•´ë‹¹ ê°’ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´
        self.latent_dim = latent_dim #ë§Œì•½ ê°ì²´ì˜ ì†ì„±ìœ¼ë¡œ ì €ì¥ì„ ì•ˆí•˜ë©´ ìƒì„±ì ë‚´ë¶€ì—ì„œë§Œ ì“°ì´ëŠ” ì§€ì—­ ë³€ìˆ˜ê°€ ë˜ê¸° ë•Œë¬¸ì— ë‹¤ë¥¸ 				                               í´ë˜ìŠ¤ì—ì„œ ì ‘ê·¼ì´ ë¶ˆê°€ëŠ¥
        
        # ì¸ì½”ë”: ê°„ë‹¨í•œ í•©ì„±ê³± ë„¤íŠ¸ì›Œí¬ (ì…ë ¥ ì±„ë„ 1 â†’ 32, 32 â†’ 64)
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),  # ê²°ê³¼: [32, image_size/2, image_size/2]
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), # ê²°ê³¼: [64, image_size/4, image_size/4]
            nn.ReLU(),
        )
        # ì¸ì½”ë”ì˜ ì¶œë ¥ ì°¨ì› ê³„ì‚° (image_sizeê°€ 32ë¼ë©´ 32//4 = 8)
        reduced_size = image_size // 4
        self.flatten_dim = 64 * reduced_size * reduced_size
        
        # ì€ë‹‰ í‘œí˜„ìœ¼ë¡œë¶€í„° ì ì¬ ë³€ìˆ˜(meanì™€ log-ë¶„ì‚°) ê³„ì‚°
        self.fc_mu = nn.Linear(self.flatten_dim, latent_dim)
        self.fc_logvar = nn.Linear(self.flatten_dim, latent_dim)
        
        # ë””ì½”ë”: latent vectorì—ì„œ ì‹œì‘í•˜ì—¬ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë³µì›
        self.decoder_input = nn.Linear(latent_dim, self.flatten_dim)
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.ReLU(),
            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),
            nn.Sigmoid(),  # í”½ì…€ ê°’ì´ [0,1] ë²”ìœ„ê°€ ë˜ë„ë¡
        )
    

    def encode(self, x):
        h = self.encoder(x)
        h = h.view(-1, self.flatten_dim) #view í•¨ìˆ˜ëŠ” í…ì„œì˜ ëª¨ì–‘ì„ ë³€ê²½, ì—¬ê¸°ì„  í…ì„œë¥¼ 4ì°¨ì›ì—ì„œ 2ì°¨ì›ìœ¼ë¡œ ë°”ê¿”ì£¼ëŠ” ì—­í• 
        mu = self.fc_mu(h)
        logvar = self.fc_logvar(h)
        return mu, logvar
    
    def reparameterize(self, mu, logvar):
        std = torch.exp(0.5 * logvar)
        eps = torch.randn_like(std)
        return mu + eps * std
    
    def decode(self, z):
        h = self.decoder_input(z)
        # [batch, 64, image_size/4, image_size/4] í˜•íƒœë¡œ reshape
        h = h.view(-1, 64, self.image_size // 4, self.image_size // 4)
        x_recon = self.decoder(h)
        return x_recon
    
    def forward(self, x):
        mu, logvar = self.encode(x)
        z = self.reparameterize(mu, logvar)
        x_recon = self.decode(z)
        return x_recon, mu, logvar

# ëª¨ë¸ ìƒì„± í›„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
model = VAE(image_size=IMAGE_SIZE, latent_dim=EMBEDDING_DIM).to(device)
print(model)
```

#### í•©ì„±ê³± ë ˆì´ì–´

**Conv2d** ëŠ” í•©ì„±ê³± ë ˆì´ì–´ë¡œ, ì´ë¯¸ì§€ê°™ì€ê±¸ ì‹ ê²½ë§ìœ¼ë¡œ ë‹¤ë£¨ê³ ì í•  ë–„ ì“°ëŠ”ë°, ì²«ë²ˆì¨° ì¸ìì—ëŠ” ì…ë ¥ì´ë¯¸ì§€ì˜ ì±„ë„ ìˆ˜, ë‘ë²ˆ ì¨°ì¸ìëŠ” ì¶œë ¥ì´ë¯¸ì§€ì˜ ì±„ë„ ìˆ˜, kernel sizeëŠ” í•©ì„±ê³±ì˜ í•„í„° ì‚¬ì´ì¦ˆ, paddingì€ ì´ë¯¸ì§€ì˜ ê°€ì¥ìë¦¬ì— 0ì˜ ê°’ì„ ê°€ì§„ í”½ì…€ì„ ë§Œë“¤ì–´ì„œ í•©ì„±ê³±í›„ì—ë„ ì‚¬ì´ì¦ˆê°€ ë§ê²Œ í•´ì£¼ê³ , strideëŠ” í•„í„°ê°€ ì´ë¯¸ì§€ë¥¼ ì§€ë‚˜ê°ˆ ë–„ ëª‡ í”½ì…€ì”© ì´ë™í•˜ëŠ”ì§€ì¸ë° 2ì¼ ê²½ìš° 2í”½ì…€ë§ˆë‹¤ ê³„ì‚° í•˜ë¯€ë¡œ ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆê°€ 1/2ê°€ ëœë‹¤.

**ConvTranspose2d**ëŠ” í•©ì„±ê³±ì˜ ì „ì¹˜ë¡œ ë””ì½”ë“œì— ì“°ì´ëŠ” ê±¸ ë³´ë©´ ì•Œë“¯ì´ ìœ„ì˜ í•©ì„±ê³±ì˜ ë°˜ëŒ€ì‘ìš©, ì¦‰ ì°¨ì›ì„ ëŠ˜ë¦¬ê³  ì´ë¯¸ì§€ë¥¼ ì¬êµ¬ì„±í•´ì£¼ëŠ” ê²ƒì´ë¼ê³  ì´í•´ í•˜ë©´ ëœë‹¤.

#### Reparameterize

**reparameterize**ëŠ” ì¬í”¼ë¼ë¯¸í„°íŠ¸ë¦­ìœ¼ë¡œ, ì•ì— ë§í–ˆë“¯ì´ ê° ì°¨ì›ì˜ ì •ê·œë¶„í¬ì—ì„œ ìƒ˜í”Œë§í•´ì„œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³ ì í•˜ëŠ”ë°, ì´ ë–„ ì´ ì •ê·œë¶„í¬ì˜ ì˜ì—­ì˜ ìƒê¹€ìƒˆëŠ” í‰ê· ê³¼(mu) ë¶„ì‚°(var)ì— ë”°ë¼ ë‹¬ë¼ì§€ë¯€ë¡œ, epsë¼ëŠ” í‘œì¤€ì •ê·œë¶„í¬(N ~ 0,1)ë¥¼ ë”°ë¡œ ë¶„ë¦¬í•´ì„œ mu + eps * stdë¼ëŠ” ì‹ìœ¼ë¡œ í‰ê· ê³¼ ë¶„ì‚°ì„ ë–„ì„œ ì € ì‹ìœ¼ë¡œ ì •ê·œë¶„í¬ë¥¼ êµ¬í˜„í•œë‹¤. ì´ê±¸ í•˜ëŠ” ì´ìœ ëŠ” VAEëŠ” í™•ë¥ ì  ìƒ˜í”Œë§ì„ ì‚¬ìš©í•˜ëŠ”ë°, ì´ ê³¼ì •ì€ ë¯¸ë¶„ ë¶ˆê°€ëŠ¥, 

ë”°ë¼ì„œ, fc_muì™€ fc_logvarë¡œë¶€í„° ê³„ì‚°ëœ *Î¼*ì™€ log*Ïƒ*2ë¥¼ ê¸°ë°˜ìœ¼ë¡œ,

*z*=*Î¼*+*Ïµ*Ã—exp(1/2log*Ïƒ*2)

í˜•ì‹ìœ¼ë¡œ *Ïµ* (í‘œì¤€ ì •ê·œë¶„í¬ì—ì„œ ìƒ˜í”Œë§í•œ ê°’)ì„ ì´ìš©í•œ ì¬íŒŒë¼ë¯¸í„°ë¼ì´ì œì´ì…˜ì„ í†µí•´ *Î¼*ì™€ *Ïƒ*ì— ì˜ì¡´ì ì¸ ìƒ˜í”Œë§ì„ ìˆ˜í–‰

ì´ ê³¼ì • ë•ë¶„ì— VAEëŠ” ì—­ì „íŒŒ ê³¼ì •ì—ì„œ gradientë¥¼ ì •ìƒì ìœ¼ë¡œ ì „ë‹¬ë°›ì„ ìˆ˜ ìˆë‹¤.

#### logë¡œ ë¶„ì‚°ì„ ê³„ì‚°í•˜ëŠ” ì´ìœ 

ã…‹â‚©ë¶„ì‚°ì€ í•­ìƒ 0 ì´ìƒì˜ ê°’ì„ ê°€ì ¸ì•¼ í•˜ì§€ë§Œ, ë¡œê·¸ë¥¼ ì·¨í•˜ë©´ ê°’ì˜ ë²”ìœ„ê°€ (âˆ’âˆ,âˆ)(âˆ’âˆ,âˆ)ê°€ ë˜ì–´ ìˆ˜ì¹˜ì ìœ¼ë¡œ ì•ˆì •ì ì¸ í•™ìŠµì´ ê°€ëŠ¥ , ë‚˜ì¤‘ì— reparameterization trickì—ì„œ ğœ=expâ¡(0.5Ã—logvar)*Ïƒ*=exp(0.5Ã—logvar)ë¡œ ê³„ì‚° 

#### view() í•¨ìˆ˜ì˜ ì—­í• 

```py
h = h.view(-1, self.flatten_dim)
```

hëŠ” í•©ì„±ê³±(convolutional) ë ˆì´ì–´ë¥¼ í†µê³¼í•œ í›„ì˜ ì¶œë ¥, 4ì°¨ì›(ë°°ì¹˜ í¬ê¸°, ì±„ë„ ìˆ˜, ë†’ì´, ë„ˆë¹„)ì˜ í˜•íƒœ, ì¦‰, (ë°°ì¹˜ í¬ê¸°, 64, reduced_size, reduced_size) í˜•íƒœì˜ í…ì„œë¥¼ (ë°°ì¹˜ í¬ê¸°, 64 * reduced_size * reduced_size) í˜•íƒœë¡œ í‰í‰í•˜ê²Œ(Flatten) ë§Œë“œëŠ” ì—­í• , ì—¬ê¸°ì„œ -1ì´ ë°°ì¹˜í¬ê¸°ë¥¼ ìë™ì ìœ¼ë¡œ ê³„ì‚° í•´ì£¼ê³ (ê°™ì€ ì²«ë²ˆì§¸ ì¸ìì— ìˆìœ¼ë‹ˆê¹Œ) ë‘ë²ˆì¨° ì¸ìì¸ flatten_dimì´ ë‚˜ë¨¸ì§€ ì°¨ì›ë“¤ì„ ëª¨ë‘ ë”í•´ì„œ í‰í‰í•œ 1ì°¨ì›ì— ë§¤í•‘í•˜ëŠ” ì—­í• ì´ë‹¤.

#### Model(data)

model(data)ë¥¼ í˜¸ì¶œí•˜ë©´, ë‚´ë¶€ì ìœ¼ë¡œ VAE í´ë˜ìŠ¤ì˜ forward() ë©”ì„œë“œê°€ ì‹¤í–‰ëŒ.

ê·¸ë¦¬í•˜ì—¬ returnê°’ìœ¼ë¡œ í‰ê· , ë¶„ì‚°, ì¬êµ¬ì„± ì´ë¯¸ì§€ë¥¼ ë°˜í™˜í•¨

```py
def loss_function(recon_x, x, mu, logvar, beta):
    # 'mean' ë°©ì‹ìœ¼ë¡œ ê³„ì‚°: ê° ë°°ì¹˜ì—ì„œ í‰ê·  ì†ì‹¤ 
    BCE = F.binary_cross_entropy(recon_x, x, reduction='mean')
    KLD = -0.5 * torch.mean(torch.sum(1 + logvar - mu.pow(2) - torch.exp(logvar), dim=1))
    loss = beta * BCE + KLD
    return loss, BCE, KLD
  
def train_model_anneal(model, dataloader, optimizer, epochs, beta, device):
    model.train()
    # ì—í¬í¬ ì´ˆë°˜ì— KL ê°€ì¤‘ì¹˜ê°€ ë‚®ê³ , íŠ¹ì • ì‹œì ë¶€í„° 1ë¡œ ê³ ì •í•˜ë„ë¡ ì„¤ì • (ì˜ˆ: ì—í¬í¬ ì ˆë°˜ê¹Œì§€ ì„ í˜• ì¦ê°€)
    for epoch in range(epochs):
        # KL weight : ì—í¬í¬ ì ˆë°˜ê¹Œì§€ 0ì—ì„œ 1ë¡œ ì„ í˜• ì¦ê°€, ê·¸ í›„ì—” 1 ìœ ì§€
        kl_weight = min(1.0, (epoch + 1) / (epochs * 0.5))
        
        total_loss, total_bce, total_kld = 0, 0, 0
        for batch_idx, (data, _) in enumerate(dataloader):
            data = data.to(device)
            optimizer.zero_grad()
            recon, mu, logvar = model(data)
            # betaë¥¼ KL weightì™€ ê³±í•´ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.
            loss, bce, kld = loss_function(recon, data, mu, logvar, beta * kl_weight)
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            total_bce += bce.item()
            total_kld += kld.item()
        
        avg_loss = total_loss / len(dataloader)
        avg_bce = total_bce / len(dataloader)
        avg_kld = total_kld / len(dataloader)
        print(f"Epoch [{epoch+1}/{epochs}], KL Weight: {kl_weight:.4f}, Loss: {avg_loss:.4f}, BCE: {avg_bce:.4f}, KL: {avg_kld:.4f}")

# ì˜µí‹°ë§ˆì´ì € ì •ì˜ (ì˜ˆ: í•™ìŠµë¥  1e-3)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

# ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
train_model_anneal(model, train_dataloader, optimizer, EPOCHS, BETA, device)
```

#### Loss

ì˜¤ì°¨ í•¨ìˆ˜ëŠ” klë°œì‚°í•­ê³¼ ì´ì§„êµì°¨ì—”íŠ¸ë¡œí”¼ì˜ í•©ìœ¼ë¡œ ê³„ì‚°í•˜ê³  ì—¬ê¸°ì„œ betaë¼ëŠ” í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¥¼ ì´ìš©í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ ì¤Œ

ë˜í•œ BCEì˜ ê³„ì‚° ë°©ì‹ì€ meanìœ¼ë¡œ ê° ë°°ì¹˜ë§ˆë‹¤ ë‚˜ì˜¤ëŠ” í‰ê·  ì†ì‹¤ì„ ì´ìš©

#### Kl_weight

KL í•­ì— ëŒ€í•œ Annealing (ê°€ì¤‘ì¹˜ ìŠ¤ì¼€ì¼ë§)

í•™ìŠµ ì´ˆë°˜ì— KL divergenceì˜ ê°€ì¤‘ì¹˜ë¥¼ ë‚®ê²Œ ì£¼ì—ˆë‹¤ê°€ ì ì°¨ ì¦ê°€ì‹œì¼œ latent ê³µê°„ì˜ collapseë¥¼ ë§‰ê³ , ë‹¤ì–‘í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ë„ë¡ í•¨.

ì¦‰, ì´ˆê¸°ì—” ì¬êµ¬ì„± ì†ì‹¤(BCE)ì— ë” ì§‘ì¤‘í•˜ê³ , ì—í¬í¬ê°€ ì§„í–‰ë¨ì— ë”°ë¼ KLì˜ ì˜í–¥ë ¥ì„ ì ì°¨ í‚¤ìš°ëŠ” ë°©ì‹

 ì ì¬ ë³€ìˆ˜(*z*)ì˜ ë‹¤ì–‘ì„±ì„ í™•ë³´í•˜ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŒ

ì´ëŸ¬í•œ ì‘ì—…ë“¤ì„ í•œ ì´ìœ ëŠ” í›„ë°© ë¶•ê´´ê°€ ì¼ì–´ë‚¬ê¸° ë–„ë¬¸ì—

### batch_idxì™€ (data, _)ì˜ ì—­í•  ë° _ì˜ ì˜ë¯¸

for batch_idx, (data, _) in enumerate(dataloader) êµ¬ë¬¸ ì„¤ëª…:

#### enumerate(dataloader)

dataloaderëŠ” í†µìƒ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ë°˜í™˜

enumerate()ë¥¼ ì‚¬ìš©í•˜ë©´ ê° ë°°ì¹˜ì— ëŒ€í•´ (ë°°ì¹˜ ì¸ë±ìŠ¤, ë°ì´í„°) í˜•íƒœì˜ íŠœí”Œì„ ì–»ê²Œ ëŒ,

ì—¬ê¸°ì„œ batch_idxëŠ” í˜„ì¬ ëª‡ ë²ˆì§¸ ë°°ì¹˜ì¸ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì •ìˆ˜

#### (data, _) ë¶€ë¶„:

dataloaderê°€ ë°˜í™˜í•˜ëŠ” ë°°ì¹˜ ë°ì´í„°ëŠ” (inputs, labels) í˜•íƒœ

ì½”ë“œì—ì„œëŠ” ì´ë¯¸ì§€ ë°ì´í„°(data)ë§Œ ì‚¬ìš©í•  ì˜ˆì •ì´ê³ , ë¼ë²¨(labels)ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ

íŒŒì´ì¬ì—ì„œ ì–¸ë”ìŠ¤ì½”ì–´(_)ëŠ” â€œì´ ë³€ìˆ˜ëŠ” ì‚¬ìš©í•˜ì§€ ì•Šê² ë‹¤â€ëŠ” ê´€ë¡€ì ì¸ í‘œí˜„ìœ¼ë¡œ, í•´ë‹¹ ìœ„ì¹˜ì˜ ê°’ì„ ë¬´ì‹œí•˜ê² ë‹¤ëŠ” ì˜ë¯¸

ë”°ë¼ì„œ (data, _)ëŠ” ì²« ë²ˆì§¸ ìš”ì†Œì—ëŠ” ì‹¤ì œ ì…ë ¥ ë°ì´í„°(ì´ë¯¸ì§€)ê°€, ë‘ ë²ˆì§¸ ìš”ì†Œì—ëŠ” ë¼ë²¨ì´ ë“¤ì–´ì˜¤ì§€ë§Œ ë¼ë²¨ì€ ì‚¬ìš©í•˜ì§€ ì•Šê² ë‹¤ëŠ” ëœ»

ì¦‰,

batch_idxëŠ” í˜„ì¬ ëª‡ ë²ˆì§¸ ë°°ì¹˜ë¥¼ ì²˜ë¦¬í•˜ê³  ìˆëŠ”ì§€ ì•Œë ¤ì£¼ê³ ,

(data, _)ì—ì„œ dataëŠ” ì‹¤ì œ ì…ë ¥ í…ì„œ(ì˜ˆ: ì´ë¯¸ì§€ ë°ì´í„°)ë¥¼, _ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë¼ë²¨ ë°ì´í„°ë¥¼ ì˜ë¯¸

```py
# í‰ê°€: ì ì¬ ê³µê°„ ì‹œê°í™”
def visualize_latent_space(model, dataloader, device):
    model.eval()
    all_mu = []
    all_labels = []
    with torch.no_grad():
        for data, labels in dataloader:
            data = data.to(device)
            _, mu, _ = model(data)
            all_mu.append(mu.cpu())
            all_labels.append(labels.cpu())
    all_mu = torch.cat(all_mu, dim=0)
    all_labels = torch.cat(all_labels, dim=0)
    
    plt.figure(figsize=(8, 6))
    scatter = plt.scatter(all_mu[:, 0], all_mu[:, 1], c=all_labels, cmap='viridis', s=2)
    plt.colorbar(scatter, label="ë ˆì´ë¸”")
    plt.xlabel("ì ì¬ ë³€ìˆ˜ z[0]")
    plt.ylabel("ì ì¬ ë³€ìˆ˜ z[1]")
    plt.title("ì ì¬ ê³µê°„ ì‹œê°í™”")
    plt.show()

visualize_latent_space(model, test_dataloader, device)
```

![image-20250209041541733](https://raw.githubusercontent.com/kirity1/blogimg/master/uPic/image-20250209041541733.png)

ì ì¬ ë²¡í„°ì˜ ë¶„í¬ì™€ ë ˆì´ë¸”ê°„ì˜ ê´€ê³„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ì‚°ì ë„ë¥¼ í‘œì‹œ

#### Model.eval()

ëª¨ë¸ì´ trainëª¨ë“œì—ì„œ í‰ê°€ëª¨ë“œë¡œ ë°”ê¿ˆì„ ëª…ì‹œí•˜ëŠ” ì½”ë“œ

#### With torch..no_grad():

ëª¨ë¸ì´ í‰ê°€ëª¨ë“œë¡œ ë³€í–ˆê¸° ë–„ë¬¸ì—, ëª¨ë¸ì„ ëŒë¦¬ëŠ” ì¤‘ì—ëŠ” gridientë¥¼ ê³„ì‚°í•˜ì§€ ì•Šê²Œ í•˜ì—¬ ì†ë„ì™€ ìµœì í™”

#### torch.cat()

torch.cat() í•¨ìˆ˜ëŠ” ì—¬ëŸ¬ ê°œì˜ í…ì„œë¥¼ í•˜ë‚˜ë¡œ ì—°ê²°í•  ë•Œ ì‚¬ìš©, ì˜ˆë¥¼ ë“¤ì–´, í…ì„œ ë¦¬ìŠ¤íŠ¸ [tensor1, tensor2, tensor3]ê°€ ìˆì„ ë•Œ,

```py
  combined = torch.cat([tensor1, tensor2, tensor3], dim=0)
```

ì´ ì½”ë“œëŠ” ì§€ì •í•œ ì°¨ì›(dim=0)ì„ ê¸°ì¤€ìœ¼ë¡œ ì„¸ í…ì„œë¥¼ í•˜ë‚˜ì˜ í…ì„œë¡œ í•©ì¹¨

ì½”ë“œì—ì„œëŠ” ì—¬ëŸ¬ ë°°ì¹˜(batch)ë¡œë¶€í„° ë‚˜ì˜¨ muì™€ labelsë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥í•œ í›„, ë‚˜ì¤‘ì— torch.cat()ì„ ì‚¬ìš©í•˜ì—¬ ì´ ë¦¬ìŠ¤íŠ¸ë“¤ì„ í•˜ë‚˜ì˜ í…ì„œë¡œ í•©ì¹˜ëŠ” ë° ì‚¬ìš©

#### mu.cpu()ì™€ labels.cpu()

.cpu()ëŠ” í˜„ì¬ í…ì„œê°€ GPU ìƒì— ìˆë‹¤ë©´ ì´ë¥¼ CPU ë©”ëª¨ë¦¬ë¡œ ì˜®ê¹€, ëª¨ë¸ê³¼ ë°ì´í„°ê°€ GPUì—ì„œ ì—°ì‚°ë˜ê³  ìˆì„ ê²½ìš°, muë‚˜ labels í…ì„œë„ GPUì— ìœ„ì¹˜,

í•˜ì§€ë§Œ, ë¦¬ìŠ¤íŠ¸ì— ì €ì¥í•˜ê±°ë‚˜ ì‹œê°í™”ë¥¼ ìœ„í•´ (ì‹œê°í™” ë„êµ¬(ì˜ˆ: matplotlib, NumPy)ì™€ í˜¸í™˜ë˜ê²Œ) NumPy ë°°ì—´ë¡œ ë³€í™˜í•˜ë ¤ë©´ CPUì— ìˆëŠ” í…ì„œì—¬ì•¼ í•¨. GPUì— ìˆëŠ” í…ì„œë¥¼ ì§ì ‘ NumPy ë³€í™˜í•˜ë ¤ê³  í•˜ë©´ ì—ëŸ¬ê°€ ë°œìƒ, ë”°ë¼ì„œ .cpu()ë¥¼ í˜¸ì¶œí•˜ì—¬ CPU ë©”ëª¨ë¦¬ë¡œ ì˜®ê¸´ í›„ .numpy() ë“±ìœ¼ë¡œ ë³€í™˜

#### scatter = plt.scatter(all_mu[:, 0], all_mu[:, 1], c=all_labels, cmap='viridis', s=2)

All_muëŠ” muë¼ëŠ” 2ì°¨ì›ì¸ í‰ê· ê°’ì„ ëª¨ì€ ë¦¬ìŠ¤íŠ¸ì´ê³ , ì—¬ê¸°ì„œ ì²«ë²ˆ ì§¸ ì¸ìëŠ” ìŠ¬ë¼ì´ì‹± í‘œê¸°ë²•ìœ¼ë¡œ í•´ë‹¹ ì°¨ì›ì˜ ëª¨ë“  ì¸ë±ìŠ¤ë¥¼ ì„ íƒí•œ ê²ƒì¸ë° ì—¬ê¸°ì„œ ì´ ìœ„ì¹˜ëŠ” ìƒ˜í”Œë°ì´í„°ë¥¼ ê°€ë¦¬í‚¨ë‹¤, all_muëŠ” shapeì´ (N, 2)ì´ê¸° ë•Œë¬¸ì— ë‘ ë²ˆì§¸ ì°¨ì›ì—ëŠ” 2ê°œì˜ ìš”ì†Œ(ê°ê° ì ì¬ ë³€ìˆ˜ì˜ ê°’)ì´ ìˆë‹¤, ì¦‰ (1,0)ê³¼ (1,1)ì˜ ì˜ë¯¸ëŠ” ë¦¬ìŠ¤íŠ¸ì¤‘ì— 2ë²ˆì¨°(ì²«ë²ˆì¨° ì¸ìê°€ 1ì´ë‹ˆê¹Œ 0,1,2,3...)ì˜ ì²«ë²ˆì¨° ì ì¬ì°¨ì›ê°’ (1,0)ê³¼ ë‘ë²ˆ ì§¸ ì ì¬ ì°¨ì›ê°’ (1,1) ë¡œ ìƒê° í•  ìˆ˜ ìˆë‹¤, ëª¨ë“  í‰ê·  ê°’ì„ ëª¨ì€ ë¦¬ìŠ¤íŠ¸ë¥¼ ìŠ¤ìºí„°ë¡œ í‘œí˜„ í•˜ê¸° ìœ„í•´ì„œ xì¸ìì™€ yì¸ìë¥¼ ì €ë ‡ê²Œ ëª¨ë“  í‰ê· ê°’ìœ¼ë¡œ ë„£ì–´ì¤˜ì„œ ìŠ¤ìºí„°í˜•íƒœë¡œ í‘œí˜„í–ˆë‹¤. ì¦‰ 

all_mu[:, 0]: ëª¨ë“  ìƒ˜í”Œì˜ ì²« ë²ˆì§¸ latent ì°¨ì› ê°’.

all_mu[:, 1]: ëª¨ë“  ìƒ˜í”Œì˜ ë‘ ë²ˆì§¸ latent ì°¨ì› ê°’.

ì´ë‹¤

#### c=all_labels

cëŠ” ê° ì‚°ì ë„ ì ì˜ ìƒ‰ìƒ(color)ì„ ì§€ì •í•˜ëŠ” ë§¤ê°œë³€ìˆ˜ì…ë‹ˆë‹¤.

ì—¬ê¸°ì„œëŠ” ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ ìƒ‰ìƒì„ all_labels ê°’ì— ë”°ë¼ ì§€ì •í•©ë‹ˆë‹¤.

ì¦‰, all_labelsì— ë“¤ì–´ìˆëŠ” ìˆ«ìë‚˜ ë²”ì£¼ ê°’ì— ë”°ë¼ ì ë“¤ì˜ ìƒ‰ìƒì´ ê²°ì •ë©ë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´, ë§Œì•½ all_labelsê°€ 0ë¶€í„° 9ê¹Œì§€ì˜ ìˆ«ìë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤ë©´, ê° ìˆ«ìë§ˆë‹¤ ë‹¤ë¥¸ ìƒ‰ìƒì´ í• ë‹¹ë˜ì–´ ì‹œê°ì ìœ¼ë¡œ êµ¬ë¶„í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.

#### cmap='viridis'

cmapì€ colormap (ìƒ‰ìƒ ë§µ)ì„ ì§€ì •í•˜ëŠ” ë§¤ê°œë³€ìˆ˜ì…ë‹ˆë‹¤.

'viridis'ëŠ” matplotlibì—ì„œ ì œê³µí•˜ëŠ” colormap ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.

ì´ colormapì€ ë°ì´í„°ì˜ ê°’ì— ë”°ë¼ ì¼ê´€ë˜ê³  ì‹œê°ì ìœ¼ë¡œ êµ¬ë¶„í•˜ê¸° ì‰¬ìš´ ìƒ‰ìƒ ê·¸ë¼ë°ì´ì…˜(ì˜ˆ, íŒŒë‘ì—ì„œ ë…¸ë‘ ë˜ëŠ” ë³´ë¼ì—ì„œ ë…¸ë‘)ìœ¼ë¡œ ì„¤ì •ë©ë‹ˆë‹¤.

ì¦‰, all_labelsì— ì˜í•´ ë§¤í•‘ëœ ê°’ë“¤ì´ 'viridis'ë¼ëŠ” colormapì— ì˜í•´ íŠ¹ì • ìƒ‰ìƒìœ¼ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.

#### s=2

sëŠ” ì‚°ì ë„ì—ì„œ ê° ì ì˜ í¬ê¸°(size)ë¥¼ ì§€ì •í•˜ëŠ” ë§¤ê°œë³€ìˆ˜ì…ë‹ˆë‹¤.

ê°’ì´ 2ë¡œ ì§€ì •ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ê° ë°ì´í„° í¬ì¸íŠ¸ê°€ ì‘ê³  ì´˜ì´˜í•˜ê²Œ ë‚˜íƒ€ë‚˜ê²Œ ë©ë‹ˆë‹¤.

ì ì˜ í¬ê¸°ëŠ” ì‹œê°í™”ì˜ ë°€ë„ë‚˜ ì „ì²´ ê·¸ë¦¼ì—ì„œì˜ ë°¸ëŸ°ìŠ¤ë¥¼ ë§ì¶”ê¸° ìœ„í•´ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```py
# 7. í‰ê°€: ì›ë³¸ ì´ë¯¸ì§€ì™€ ì¬êµ¬ì„± ì´ë¯¸ì§€ ë¹„êµ
def plot_reconstructions(model, dataloader, device, n=10):
    model.eval()
    data, _ = next(iter(dataloader))
    data = data.to(device)
    with torch.no_grad():
        recon, _, _ = model(data)
    plt.figure(figsize=(20, 4))
    for i in range(n):
        # ì›ë³¸ ì´ë¯¸ì§€ ì¶œë ¥
        ax = plt.subplot(2, n, i + 1)
        plt.imshow(data[i].cpu().squeeze(), cmap='gray')
        ax.axis('off')
        # ì¬êµ¬ì„± ì´ë¯¸ì§€ ì¶œë ¥
        ax = plt.subplot(2, n, i + n + 1)
        plt.imshow(recon[i].cpu().squeeze(), cmap='gray')
        ax.axis('off')
    plt.suptitle("ì›ë³¸ ì´ë¯¸ì§€ì™€ ì¬êµ¬ì„± ì´ë¯¸ì§€")
    plt.show()

plot_reconstructions(model, test_dataloader, device, n=10)
```

![image-20250209041554860](https://raw.githubusercontent.com/kirity1/blogimg/master/uPic/image-20250209041554860.png)

ì›ë³¸ ì´ë¯¸ì§€ì™€ ì¬êµ¬ì„±ëœ ì´ë¯¸ì§€ì˜ ë¹„êµë¥¼ í†µí•´ ëª¨ë¸ì˜ ì¬êµ¬ì„± ì„±ëŠ¥ì„ í™•ì¸

#### .squeeze()

í…ì„œì˜ ë¶ˆí•„ìš”í•œ ì°¨ì›(í¬ê¸°ê°€ 1ì¸ ì°¨ì›)ì„ ì œê±°í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, [1, 1, IMAGE_SIZE, IMAGE_SIZE]ë¥¼ [IMAGE_SIZE, IMAGE_SIZE]ë¡œ ë§Œë“¤ì–´ì„œ ì´ë¯¸ì§€ í˜•íƒœë¡œ ì“°ê¸° ì¢‹ê²Œ í•©ë‹ˆë‹¤.

```py
# 8. í‰ê°€: ì ì¬ ê³µê°„ ê²©ì ìƒ˜í”Œë§ìœ¼ë¡œ ì´ë¯¸ì§€ ìƒì„± (ì ì¬ ì°¨ì›ì´ 2ì¸ ê²½ìš°ì—ë§Œ ìˆ˜í–‰)
def plot_latent_grid(model, device, image_size, latent_dim, grid_size=15):
    if latent_dim != 2:
        print("ì ì¬ ì°¨ì›ì´ 2ê°€ ì•„ë‹ˆì–´ì„œ ê²©ì ìƒ˜í”Œë§ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    model.eval()
    # í‘œì¤€ ì •ê·œë¶„í¬ì˜ ë¶„ìœ„ìˆ˜(quantile)ë¥¼ ì´ìš©í•œ grid ìƒì„±
    grid_x = torch.linspace(-3, 3, grid_size)
    grid_y = torch.linspace(-3, 3, grid_size)
    generated_images = []
    with torch.no_grad():
        for yi in grid_y:
            row_images = []
            for xi in grid_x:
                z = torch.tensor([[xi, yi]], dtype=torch.float32).to(device)
                x_decoded = model.decode(z)
                # ì¶œë ¥ í…ì„œ shape: [1, 1, IMAGE_SIZE, IMAGE_SIZE]
                img = x_decoded.cpu().squeeze().numpy()
                row_images.append(img)
            generated_images.append(row_images)
    
    # ê²©ì í˜•ì‹ì˜ í•˜ë‚˜ì˜ í° ì´ë¯¸ì§€ë¡œ ì¡°í•©
    figure = np.zeros((grid_size * image_size, grid_size * image_size))
    for i in range(grid_size):
        for j in range(grid_size):
            figure[i * image_size:(i + 1) * image_size, j * image_size:(j + 1) * image_size] = generated_images[i][j]
    
    plt.figure(figsize=(10, 10))
    plt.imshow(figure, cmap='gray')
    plt.title("ì ì¬ ê³µê°„ì—ì„œ ê· ë“± ìƒ˜í”Œë§í•˜ì—¬ ìƒì„±í•œ ì´ë¯¸ì§€ ê·¸ë¦¬ë“œ")
    plt.axis('off')
    plt.show()

plot_latent_grid(model, device, IMAGE_SIZE, EMBEDDING_DIM, grid_size=15)
```

![image-20250209041606718](https://raw.githubusercontent.com/kirity1/blogimg/master/uPic/image-20250209041606718.png)

latent ê³µê°„ì´ 2ì°¨ì›ì¼ ë•Œ, ì ì¬ ê³µê°„ì˜ ì—¬ëŸ¬ ì§€ì ì„ ìƒ˜í”Œë§í•˜ì—¬ ë””ì½”ë”ê°€ ìƒì„±í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ê²©ì í˜•íƒœë¡œ ë³´ì—¬ì¤Œ
